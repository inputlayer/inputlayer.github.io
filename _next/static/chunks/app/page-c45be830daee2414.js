(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{439:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(8340).A)("Shield",[["path",{d:"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z",key:"oel41y"}]])},718:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(8340).A)("Brain",[["path",{d:"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z",key:"l5xja"}],["path",{d:"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z",key:"ep3f8r"}],["path",{d:"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4",key:"1p4c4q"}],["path",{d:"M17.599 6.5a3 3 0 0 0 .399-1.375",key:"tmeiqw"}],["path",{d:"M6.003 5.125A3 3 0 0 0 6.401 6.5",key:"105sqy"}],["path",{d:"M3.477 10.896a4 4 0 0 1 .585-.396",key:"ql3yin"}],["path",{d:"M19.938 10.5a4 4 0 0 1 .585.396",key:"1qfode"}],["path",{d:"M6 18a4 4 0 0 1-1.967-.516",key:"2e4loj"}],["path",{d:"M19.967 17.484A4 4 0 0 1 18 18",key:"159ez6"}]])},1337:(e,t,n)=>{"use strict";n.d(t,{cn:()=>s});var a=n(9722),r=n(622);function s(...e){return(0,r.QP)((0,a.$)(e))}},1628:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(8340).A)("ArrowRight",[["path",{d:"M5 12h14",key:"1ays0h"}],["path",{d:"m12 5 7 7-7 7",key:"xquz4c"}]])},2680:(e,t,n)=>{"use strict";n.d(t,{Z:()=>i});var a=n(5155),r=n(8500),s=n.n(r);function i({slug:e,title:t,date:n,author:r,excerpt:i,category:o}){return(0,a.jsxs)(s(),{href:`/blog/${e}/`,className:"group rounded-xl border border-border bg-card p-6 space-y-3 transition-colors hover:border-primary/30 hover:bg-card/80",children:[o&&(0,a.jsx)("span",{className:"inline-flex items-center rounded-full border border-border bg-secondary/50 px-2.5 py-0.5 text-xs font-medium text-muted-foreground",children:o}),(0,a.jsx)("h3",{className:"text-lg font-semibold group-hover:text-primary transition-colors line-clamp-2",children:t}),i&&(0,a.jsx)("p",{className:"text-sm text-muted-foreground line-clamp-3",children:i}),(0,a.jsxs)("div",{className:"flex items-center gap-2 text-xs text-muted-foreground",children:[n&&(0,a.jsx)("time",{dateTime:n,children:new Date(n).toLocaleDateString("en-US",{year:"numeric",month:"long",day:"numeric"})}),n&&r&&(0,a.jsx)("span",{children:"\xb7"}),r&&(0,a.jsx)("span",{children:r})]})]})}},3322:(e,t,n)=>{"use strict";n.d(t,{nW:()=>l});let a=new Set(["count_distinct","count","sum","avg","top_k_threshold","top_k","within_radius","min","max"]),r=new Set(["euclidean_int8","euclidean","cosine_int8","cosine","dot_int8","dot","manhattan_int8","manhattan","normalize","vec_dim","vec_add","vec_scale","quantize_linear","quantize_symmetric","dequantize_scaled","dequantize","lsh_multi_probe","lsh_bucket","lsh_probes","hnsw_nearest","time_decay_linear","time_decay","time_diff","time_add","time_sub","time_now","time_before","time_after","time_between","within_last","intervals_overlap","interval_contains","interval_duration","point_in_interval","abs_int64","abs_float64","abs","sqrt","pow","log","exp","sin","cos","tan","floor","ceil","sign","to_float","to_int","len","upper","lower","trim","substr","replace","concat","min_val","max_val"]),s=new Set(["type","true","false","int","string","bool","float","list","vector","timestamp"]),i=RegExp([/\/\*[\s\S]*?(?:\*\/|$)/.source,/\/\/[^\n]*/.source,/"(?:[^"\\]|\\.)*(?:"|$)/.source,/\.(?:kg\s+(?:create|list|use|drop)|rel|rule\s+(?:list|drop|remove|def|clear|edit|query)|session\s+(?:clear|drop)|index\s+(?:list|create|drop|stats|rebuild)|user\s+(?:list|create|drop|password|role)|apikey\s+(?:create|list|revoke)|kg|rule|session|index|user|apikey|load|compact|status|help|quit|exit|explain|\?|q)\b/.source,/<-/.source,/>=|<=|!=/.source,/\?(?=[A-Za-z])/.source,/[+\-](?=[a-z"~\[])/.source,/~(?=[a-z])/.source,/!(?=[A-Za-z])/.source,/\b[0-9]+\.[0-9]+(?:[eE][+\-]?[0-9]+)?\b/.source,/\b[0-9]+\b/.source,/\b[A-Za-z_][A-Za-z0-9_]*\b/.source,/[+\-*/%]/.source,/[<>=]/.source,/[()[\]{},.:;]/.source,/\s+/.source,/./.source].join("|"),"g"),o={comment:"syn-comment",string:"syn-string",meta:"syn-meta",query:"syn-query",arrow:"syn-arrow",operator:"syn-operator",negation:"syn-negation",comparison:"syn-comparison",number:"syn-number",aggregate:"syn-aggregate",builtin:"syn-builtin",keyword:"syn-keyword",variable:"syn-variable",identifier:"syn-identifier","body-identifier":"syn-body-id",arith:"syn-arith",punctuation:"syn-punct",whitespace:"",unknown:""};function l(e){return function(e){let t="";for(let n of e){let e=n.text.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;"),a=o[n.kind];a?t+=`<span class="${a}">${e}</span>`:t+=e}return t.endsWith("\n")||(t+="\n"),t}(function(e){let t,n=[],o=!1;for(i.lastIndex=0;null!==(t=i.exec(e));){let e=t[0],i=function(e,t){if(e.startsWith("/*")||e.startsWith("//"))return"comment";if(e.startsWith('"'))return"string";if(e.startsWith("."))return"meta";if("<-"===e)return"arrow";if(">="===e||"<="===e||"!="===e)return"comparison";if("?"===e&&1===e.length)return"query";if(/^[+\-]$/.test(e))return"arith";if("~"===e)return"operator";if("!"===e)return"negation";if(/^[0-9]/.test(e))return"number";if(/^[A-Za-z_]/.test(e))return a.has(e)?"aggregate":r.has(e)?"builtin":s.has(e)?"keyword":/^[A-Z_]/.test(e)?"variable":/^[a-z]/.test(e)?t?"body-identifier":"identifier":"unknown";return/^[+\-*/%]$/.test(e)?"arith":/^[<>=]$/.test(e)?"comparison":/^[()[\]{},.:;]$/.test(e)?"punctuation":/^\s+$/.test(e)?"whitespace":"unknown"}(e,o);if("arrow"===i)o=!0;else if("whitespace"===i&&e.includes("\n")){let t=e.substring(e.lastIndexOf("\n")+1);/[ \t]/.test(t)||(o=!1)}n.push({kind:i,text:e})}return n}(e))}},5660:(e,t,n)=>{"use strict";n.d(t,{D:()=>c});var a=n(5155),r=n(8500),s=n.n(r),i=n(8920),o=n(2164);let l={Product:[{label:"Features",href:"/#features"},{label:"Use Cases",href:"/use-cases/"},{label:"Compare",href:"/compare/"},{label:"Demo",href:"https://demo.inputlayer.ai",external:!0}],Resources:[{label:"Documentation",href:"/docs/"},{label:"Blog",href:"/blog/"},{label:"Quickstart",href:"/docs/guides/quickstart/"},{label:"Python SDK",href:"/docs/guides/python-sdk/"}],Company:[{label:"GitHub",href:"https://github.com/inputlayer/inputlayer",external:!0},{label:"License",href:"https://github.com/inputlayer/inputlayer/blob/main/LICENSE",external:!0}],Community:[{label:"Star on GitHub",href:"https://github.com/inputlayer/inputlayer",external:!0},{label:"Contributing",href:"https://github.com/inputlayer/inputlayer/blob/main/CONTRIBUTING.md",external:!0}]};function c(){return(0,a.jsx)("footer",{className:"border-t border-border/50 bg-card/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-12",children:[(0,a.jsx)("div",{className:"grid grid-cols-2 gap-8 md:grid-cols-4 lg:gap-12",children:Object.entries(l).map(([e,t])=>(0,a.jsxs)("div",{children:[(0,a.jsx)("h3",{className:"text-sm font-semibold text-foreground mb-3",children:e}),(0,a.jsx)("ul",{className:"space-y-2",children:t.map(e=>(0,a.jsx)("li",{children:e.external?(0,a.jsxs)("a",{href:e.href,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors",children:[e.label,(0,a.jsx)(o.A,{className:"h-3 w-3"})]}):(0,a.jsx)(s(),{href:e.href,className:"text-sm text-muted-foreground hover:text-foreground transition-colors",children:e.label})},e.label))})]},e))}),(0,a.jsxs)("div",{className:"mt-10 flex flex-col sm:flex-row items-center justify-between gap-4 border-t border-border/50 pt-8",children:[(0,a.jsxs)("div",{className:"flex items-center gap-4",children:[(0,a.jsx)(i.g,{size:"sm"}),(0,a.jsx)("span",{className:"text-sm text-muted-foreground",children:"AGPL-3.0 License"})]}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground",children:"A symbolic reasoning engine for AI agents."})]})]})})}},6360:(e,t,n)=>{Promise.resolve().then(n.bind(n,8473))},7397:(e,t,n)=>{"use strict";n.d(t,{D:()=>A});var a=n(5155),r=n(8500),s=n.n(r),i=n(2115),o=n(8920),l=n(1900),c=n(6999),h=n(460),d=n(2442),u=n(8460),m=n(1337);let p=(0,u.F)("inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",{variants:{variant:{default:"bg-primary text-primary-foreground hover:bg-primary/90",destructive:"bg-destructive text-white hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",outline:"border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50",secondary:"bg-secondary text-secondary-foreground hover:bg-secondary/80",ghost:"hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50",link:"text-primary underline-offset-4 hover:underline"},size:{default:"h-9 px-4 py-2 has-[>svg]:px-3",sm:"h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",lg:"h-10 rounded-md px-6 has-[>svg]:px-4",icon:"size-9","icon-sm":"size-8","icon-lg":"size-10"}},defaultVariants:{variant:"default",size:"default"}});function g({className:e,variant:t,size:n,asChild:r=!1,...s}){let i=r?d.DX:"button";return(0,a.jsx)(i,{"data-slot":"button",className:(0,m.cn)(p({variant:t,size:n,className:e})),...s})}function y(){let{theme:e,setTheme:t}=(0,h.D)(),[n,r]=i.useState(!1);return(i.useEffect(()=>{r(!0)},[]),n)?(0,a.jsxs)(g,{variant:"ghost",size:"icon",className:"h-9 w-9",onClick:()=>t("dark"===e?"light":"dark"),children:[(0,a.jsx)(l.A,{className:"h-4 w-4 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0"}),(0,a.jsx)(c.A,{className:"absolute h-4 w-4 rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100"}),(0,a.jsx)("span",{className:"sr-only",children:"Toggle theme"})]}):(0,a.jsx)(g,{variant:"ghost",size:"icon",className:"h-9 w-9",children:(0,a.jsx)(l.A,{className:"h-4 w-4"})})}var f=n(3210),b=n(9857),v=n(2164);let x=[{label:"Docs",href:"/docs/"},{label:"Blog",href:"/blog/"},{label:"Use Cases",href:"/use-cases/"},{label:"Compare",href:"/compare/"},{label:"Demo",href:"https://demo.inputlayer.ai",external:!0}];function w(){let[e,t]=(0,i.useState)(!1);return(0,a.jsxs)("div",{className:"md:hidden",children:[(0,a.jsx)("button",{onClick:()=>t(!e),className:"inline-flex items-center justify-center rounded-md p-2 text-muted-foreground hover:text-foreground hover:bg-secondary transition-colors","aria-label":e?"Close menu":"Open menu",children:e?(0,a.jsx)(f.A,{className:"h-5 w-5"}):(0,a.jsx)(b.A,{className:"h-5 w-5"})}),e&&(0,a.jsx)("div",{className:"absolute left-0 right-0 top-14 z-50 border-b border-border bg-background p-4",children:(0,a.jsx)("nav",{className:"flex flex-col gap-3",children:x.map(e=>e.external?(0,a.jsxs)("a",{href:e.href,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1.5 rounded-md px-3 py-2 text-sm text-muted-foreground hover:text-foreground hover:bg-secondary transition-colors",onClick:()=>t(!1),children:[e.label,(0,a.jsx)(v.A,{className:"h-3 w-3"})]},e.label):(0,a.jsx)(s(),{href:e.href,className:"rounded-md px-3 py-2 text-sm text-muted-foreground hover:text-foreground hover:bg-secondary transition-colors",onClick:()=>t(!1),children:e.label},e.label))})})]})}var k=n(4290),j=n(7026);function N(){let[e,t]=(0,i.useState)(null),[n,r]=(0,i.useState)(null);return(0,i.useEffect)(()=>{fetch("https://api.github.com/repos/inputlayer/inputlayer").then(e=>e.ok?e.json():null).then(e=>{e?.stargazers_count!=null&&t(e.stargazers_count),e?.forks_count!=null&&r(e.forks_count)}).catch(()=>{})},[]),(0,a.jsxs)("div",{className:"inline-flex items-center gap-1.5",children:[(0,a.jsxs)("a",{href:"https://github.com/inputlayer/inputlayer",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1.5 rounded-md border border-border bg-secondary/50 px-2.5 py-1 text-xs font-medium text-muted-foreground transition-colors hover:text-foreground hover:bg-secondary",children:[(0,a.jsx)(k.A,{className:"h-3.5 w-3.5"}),null!==e?(0,a.jsx)("span",{children:e>=1e3?`${(e/1e3).toFixed(1)}k`:e}):(0,a.jsx)("span",{children:"Star"})]}),(0,a.jsxs)("a",{href:"https://github.com/inputlayer/inputlayer/fork",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1.5 rounded-md border border-border bg-secondary/50 px-2.5 py-1 text-xs font-medium text-muted-foreground transition-colors hover:text-foreground hover:bg-secondary",children:[(0,a.jsx)(j.A,{className:"h-3.5 w-3.5"}),null!==n?(0,a.jsx)("span",{children:n>=1e3?`${(n/1e3).toFixed(1)}k`:n}):(0,a.jsx)("span",{children:"Fork"})]})]})}function A(){return(0,a.jsx)("header",{className:"sticky top-0 z-50 w-full border-b border-border/50 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60",children:(0,a.jsxs)("div",{className:"flex h-14 items-center px-6",children:[(0,a.jsx)(s(),{href:"/",className:"mr-8",children:(0,a.jsx)(o.g,{size:"md"})}),(0,a.jsxs)("nav",{className:"hidden md:flex items-center gap-6 text-sm",children:[(0,a.jsx)(s(),{href:"/docs/",className:"text-muted-foreground transition-colors hover:text-foreground",children:"Docs"}),(0,a.jsx)(s(),{href:"/blog/",className:"text-muted-foreground transition-colors hover:text-foreground",children:"Blog"}),(0,a.jsx)(s(),{href:"/use-cases/",className:"text-muted-foreground transition-colors hover:text-foreground",children:"Use Cases"}),(0,a.jsx)(s(),{href:"/compare/",className:"text-muted-foreground transition-colors hover:text-foreground",children:"Compare"}),(0,a.jsxs)("a",{href:"https://demo.inputlayer.ai",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1 text-muted-foreground transition-colors hover:text-foreground",children:["Demo",(0,a.jsx)(v.A,{className:"h-3 w-3"})]})]}),(0,a.jsxs)("div",{className:"ml-auto flex items-center gap-3",children:[(0,a.jsx)(N,{}),(0,a.jsx)(y,{}),(0,a.jsx)(w,{})]})]})})}},8473:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>q});var a=n(5155),r=n(8500),s=n.n(r),i=n(2115),o=n(7397),l=n(5660),c=n(2680),h=n(3322);let d=[{slug:"why-vector-search-alone-fails",title:"Why Vector Search Alone Fails Your AI Agent",date:"2026-02-25",author:"InputLayer Team",category:"Architecture",excerpt:"Vector similarity finds things that look like the answer. But when the answer requires connecting facts across different sources, similarity search hits a wall.",content:"\n# Why Vector Search Alone Fails Your AI Agent\n\nImagine you're building a healthcare AI agent. A patient asks: *\"Can I eat shrimp tonight?\"*\n\nYour agent does what it's supposed to do - it embeds the question and runs a similarity search. Back come the results: shrimp recipes, nutritional info, some allergy FAQs. All genuinely relevant to the words \"eat shrimp.\"\n\nAll completely wrong for this patient.\n\n## What went wrong\n\nThe correct answer is \"No, and it could be dangerous.\" But that answer doesn't live in any single document. It lives across three separate pieces of information:\n\n```chain\nSarah takes Amiodarone\n-- interacts with\nIodine\n-- found in\nShrimp\n=> Shrimp is risky for Sarah\n```\n\nThe patient takes a specific medication. That medication interacts with iodine. Shrimp is high in iodine. Each fact sits in a different database. And the phrase \"shrimp dinner\" has zero similarity to \"medication contraindications\" - they share no words, no concepts, no embedding overlap.\n\nThis is the core problem: **the connection between these facts is logical, not semantic.** You can't find it by looking for similar text. You have to follow a chain of relationships from one fact to the next.\n\n## This shows up everywhere\n\nThe healthcare example is vivid, but this same pattern appears in every domain where answers require connecting multiple facts.\n\n```steps\nA compliance analyst asks: \"Is this transaction suspicious?\" :: The vector DB finds similar transactions. It misses that Entity A is owned by Entity B, which is on a sanctions list.\nAn employee searches for Q3 revenue reports :: The vector DB returns 40 matches. It can't check whether this employee has permission to see any of them through the org hierarchy.\nA supply chain manager asks about disruptions :: The vector DB finds news about port closures. It can't trace which of your suppliers use that port, and which products are affected.\n```\n\nIn every case, the answer requires **following a chain of connected facts** - not finding a similar document. The information exists, but it's spread across different sources, and the connections between them are structural, not textual.\n\n## Why more RAG tricks won't help\n\nWhen teams hit this problem, the first instinct is to optimize the retrieval pipeline. Better chunking. Better embeddings. Hybrid search. Re-ranking.\n\nNone of these help, because the problem isn't retrieval quality. The retrieval is working perfectly - it's finding the most similar content. The problem is that similarity is the wrong tool for the job.\n\n```flow\nUser question -> Embed -> Similarity search -> Similar documents\n```\n\nThis pipeline answers: *\"What text looks most like my question?\"* That's great when the answer exists in a single document. It fails when the answer must be **derived** by connecting facts from different places.\n\n## What teams end up building\n\nTo work around this, teams start adding systems. A graph database for relationships. A rules engine for business logic. An authorization service for access control. Application code to stitch it all together.\n\n```flow\nUser question -> Vector DB [primary] -> Graph DB -> Rules engine -> Auth service -> Reconcile in app code\n```\n\nThe reasoning logic ends up scattered across services. When a fact changes, you have to propagate the change across all of them. It works, but it's fragile, and each new capability makes it more fragile.\n\n## What it looks like with a reasoning layer\n\nInputLayer sits alongside your vector database and handles the part that similarity search can't: following chains of logic and deriving conclusions.\n\n```flow\nUser question -> Your vector DB -> Similar documents\n```\n\n```flow\nUser question -> InputLayer [primary] -> Derived conclusions\n```\n\nYou keep your vector database for what it's good at - finding similar content. You add InputLayer for questions that require reasoning: traversing relationships, evaluating rules, checking permissions through hierarchies.\n\nWhen the patient's medication list changes, InputLayer automatically updates every downstream risk assessment. When an employee changes departments, their permissions recalculate through the org hierarchy. When a corporate ownership structure shifts, the compliance analysis adjusts. All of this happens incrementally - only the affected conclusions recompute, not the entire knowledge base.\n\n## Getting started\n\nInputLayer is open-source and runs in a single Docker container:\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nThe [quickstart guide](/docs/guides/quickstart/) walks you through building your first knowledge graph in about 10 minutes.",toc:[{level:2,text:"What went wrong",id:"what-went-wrong"},{level:2,text:"This shows up everywhere",id:"this-shows-up-everywhere"},{level:2,text:"Why more RAG tricks won't help",id:"why-more-rag-tricks-wont-help"},{level:2,text:"What teams end up building",id:"what-teams-end-up-building"},{level:2,text:"What it looks like with a reasoning layer",id:"what-it-looks-like-with-a-reasoning-layer"},{level:2,text:"Getting started",id:"getting-started"}]},{slug:"inputlayer-in-10-minutes",title:"InputLayer in 10 Minutes: From Docker to Your First Knowledge Graph",date:"2026-02-20",author:"InputLayer Team",category:"Tutorial",excerpt:"A hands-on tutorial to get InputLayer running and build your first knowledge graph with rules, recursive queries, and vector search.",content:"\n# InputLayer in 10 Minutes: From Docker to Your First Knowledge Graph\n\nBy the end of this tutorial, you'll have a running knowledge graph that can answer questions no regular database can handle. We'll build it step by step, and I'll explain what's happening at each point.\n\n## Step 1: Start InputLayer\n\nRun this in your terminal:\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nYou'll see InputLayer start up and print a message telling you it's ready. That's it - no config files, no setup.\n\n## Step 2: Open the REPL\n\nNow you need a way to talk to InputLayer. Open your browser and go to:\n\n```\nhttp://localhost:8080\n```\n\nThis opens InputLayer's interactive REPL - a command line where you can type queries and see results immediately. Think of it like a SQL console, but for knowledge graphs.\n\nYou can also use the [Python SDK](/docs/guides/python-sdk/) or the [REST API](/docs/guides/configuration/), but the REPL is the fastest way to explore.\n\n## Step 3: Store some facts\n\nLet's model a small organization. In the REPL, you'll store three facts about who manages whom:\n\n```\nAlice manages Bob\nBob manages Charlie\nBob manages Diana\n```\n\nHere's what that looks like as a structure:\n\n```tree\nAlice [primary]\n  Bob\n    Charlie\n    Diana\n```\n\nThat's the entire org chart. Three facts, four people. InputLayer stores these immediately - no schema to define, no tables to create.\n\nYou can already ask simple questions: \"Who does Bob manage?\" returns Charlie and Diana. \"Who manages Bob?\" returns Alice. These are direct lookups, nothing special yet.\n\n## Step 4: Define a rule\n\nThis is the step where InputLayer becomes fundamentally different from a regular database.\n\nWe want to answer: *\"Who does Alice have authority over?\"* Alice manages Bob directly. But does she have authority over Charlie? She doesn't manage Charlie - Bob does. But intuitively, yes - because she manages the person who manages Charlie.\n\nYou express this intuition as a rule:\n\n```note\ntype: tip\nIf person A manages person B, then A has authority over B.\nAnd if A has authority over B, and B has authority over C, then A has authority over C too.\n```\n\nThat second sentence is the important part - it's recursive. It says: authority flows down through the management chain, no matter how deep it goes.\n\nWhen you enter this rule, InputLayer immediately starts reasoning. It applies the rule over and over until there are no more conclusions to draw. Here's what it figures out:\n\n```steps\nAlice manages Bob, so Alice has authority over Bob :: Direct - from the fact you stored\nBob manages Charlie, so Bob has authority over Charlie :: Direct - from the fact you stored\nBob manages Diana, so Bob has authority over Diana :: Direct - from the fact you stored\nAlice has authority over Bob, and Bob has authority over Charlie... :: Following the chain one more step\nAlice has authority over Charlie :: Derived - the engine figured this out [success]\nAlice has authority over Diana :: Derived - same logic, through Bob [success]\n```\n\nFive authority relationships, derived automatically from three facts and one rule.\n\n## Step 5: Ask a question\n\nNow query: *\"Who does Alice have authority over?\"*\n\nThe answer: **Bob, Charlie, and Diana.**\n\nAlice doesn't manage Charlie or Diana directly. But the engine followed the chain and figured it out. This is something a regular database can't do - it required two hops of reasoning.\n\n## Step 6: Add vector search\n\nInputLayer supports vector embeddings alongside logical reasoning. This is where it gets powerful, because you can combine the two in a single query.\n\nSay each person has authored some documents, and each document has an embedding vector. You can now ask something that would normally require multiple systems:\n\n*\"Find documents similar to my query, but only from people that Alice has authority over.\"*\n\n```steps\nResolve Alice's authority chain :: The engine figures out: Bob, Charlie, Diana\nFind documents authored by those people :: Filters to their documents only\nRank by semantic similarity to the query :: Returns the most relevant ones [success]\n```\n\nReasoning and retrieval, combined in one pass. No separate authorization service, no glue code.\n\n## Step 7: See incremental updates\n\nAdd a new fact: Diana now manages a new employee, Frank.\n\n```tree\nAlice [primary]\n  Bob\n    Charlie\n    Diana\n      Frank [success]\n```\n\nQuery authority again. Frank shows up in Alice's results immediately - even though you never told the system about Alice's relationship to Frank. The engine derived it: Alice has authority over Diana, Diana manages Frank, therefore Alice has authority over Frank.\n\nThe important part: InputLayer didn't recompute everything from scratch. It identified that the new fact only affects a small part of the graph and updated just that. On a 2,000-node graph, this is over **1,600x faster** than recomputing everything.\n\n## Step 8: See correct retraction\n\nRemove the fact that Bob manages Diana.\n\n```tree\nAlice [primary]\n  Bob\n    Charlie\n```\n\nQuery authority again. Diana and Frank are gone from Alice's results. But Bob still has authority over Charlie - that relationship doesn't depend on Diana at all.\n\nHere's the subtle part: what if Diana had reported to Alice through *two* paths? Say both Bob and Eve managed Diana. Removing Bob's management of Diana shouldn't remove Alice's authority over Diana if the Eve path still exists. InputLayer tracks this automatically - a conclusion only disappears when *all* paths supporting it are gone.\n\n## What you just built\n\nIn about 10 minutes, you've used:\n\n| Capability | What happened |\n|---|---|\n| Knowledge graph | Stored facts about people and relationships |\n| Recursive reasoning | A rule derived authority chains automatically |\n| Vector search | Combined similarity with logical reasoning |\n| Incremental updates | New facts propagated in milliseconds |\n| Correct retraction | Removed facts cleaned up precisely |\n\nThese capabilities normally require stitching together multiple systems - a graph database, a vector database, a rules engine, application code. InputLayer handles them all in one place.\n\n## Next steps\n\nThe [data modeling guide](/docs/guides/core-concepts/) covers how to design your knowledge graph schema. The [vectors guide](/docs/guides/vectors/) dives deeper into similarity search and HNSW indexes. And the [Python SDK](/docs/guides/python-sdk/) is the fastest way to integrate InputLayer into your applications.",toc:[{level:2,text:"Step 1: Start InputLayer",id:"step-1-start-inputlayer"},{level:2,text:"Step 2: Open the REPL",id:"step-2-open-the-repl"},{level:2,text:"Step 3: Store some facts",id:"step-3-store-some-facts"},{level:2,text:"Step 4: Define a rule",id:"step-4-define-a-rule"},{level:2,text:"Step 5: Ask a question",id:"step-5-ask-a-question"},{level:2,text:"Step 6: Add vector search",id:"step-6-add-vector-search"},{level:2,text:"Step 7: See incremental updates",id:"step-7-see-incremental-updates"},{level:2,text:"Step 8: See correct retraction",id:"step-8-see-correct-retraction"},{level:2,text:"What you just built",id:"what-you-just-built"},{level:2,text:"Next steps",id:"next-steps"}]},{slug:"benchmarks-1587x-faster-recursive-queries",title:"Benchmarks: 1,587x Faster Recursive Queries with Differential Dataflow",date:"2026-02-15",author:"InputLayer Team",category:"Engineering",excerpt:"How InputLayer's incremental computation engine delivers sub-millisecond updates on recursive queries over large graphs. The architecture behind the numbers.",content:"\n# Benchmarks: 1,587x Faster Recursive Queries with Differential Dataflow\n\nWhen a single fact changes in a knowledge graph with 400,000 derived relationships, how much work should the system do?\n\nThe naive answer: recompute all 400,000 relationships from scratch. That's what most systems do. It takes 11 seconds.\n\nThe smart answer: figure out which relationships are actually affected by the change and update only those. That takes 6.83 milliseconds.\n\nThat's a **1,652x** difference. And it's the difference between \"we can check permissions in real time\" and \"we run a batch job overnight and hope nothing changes before morning.\"\n\n## The benchmark setup\n\nWe wanted to test something that reflects real-world usage, not a synthetic micro-benchmark. So we picked a common pattern: computing transitive authority in an organizational graph. This is the same kind of computation you'd need for access control chains, supply chain risk propagation, or entity resolution across corporate structures.\n\n```flow\n2,000 nodes -> ~6,000 edges -> ~400,000 derived relationships\n```\n\n```note\ntype: info\nThe test: add one new edge, then measure how long it takes to update all derived relationships.\n```\n\nThe 400,000 derived relationships come from the transitive nature of authority. If A manages B and B manages C, then A has authority over C. Follow that logic through 2,000 nodes with an average depth of 8-10 levels, and the number of derived relationships grows fast.\n\n## The results\n\n| Approach | Time | What it does |\n|---|---|---|\n| Full recomputation | 11,280 ms | Throws away all 400,000 derived relationships, re-derives them all |\n| InputLayer (incremental) | 6.83 ms | Identifies affected relationships, updates only those |\n\nFull recomputation doesn't care that you only changed one edge. It treats the entire graph as dirty and rebuilds everything. InputLayer's engine, on the other hand, traces the impact of the change through the derivation graph and touches only what's affected.\n\nTo put 6.83ms in perspective: that's fast enough to run inline with an API request. You can check permissions, compute supply chain exposure, or resolve entity relationships at query time rather than pre-computing them in a batch process.\n\n## The scaling story\n\nHere's where it gets really interesting. The incremental advantage doesn't stay constant as your graph grows - it gets *dramatically* better.\n\n| Graph size | Derived relationships | Full recompute | Incremental | Speedup |\n|---|---|---|---|---|\n| 500 nodes | ~25,000 | 420 ms | 1.2 ms | **350x** |\n| 1,000 nodes | ~100,000 | 2,800 ms | 3.1 ms | **903x** |\n| 2,000 nodes | ~400,000 | 11,280 ms | 6.83 ms | **1,652x** |\n\nLook at how the two columns grow. Full recomputation grows roughly quadratically - double the nodes, quadruple the time. But incremental updates grow much slower, because most single-fact changes only ripple through a small portion of the graph.\n\n```steps\n500 nodes: 420ms full vs 1.2ms incremental :: 350x faster\n1,000 nodes: 2,800ms full vs 3.1ms incremental :: 903x faster\n2,000 nodes: 11,280ms full vs 6.83ms incremental :: 1,652x faster [primary]\n```\n\nThis scaling behavior is fundamental, not accidental. Full recomputation has to process the entire graph regardless of what changed. Incremental updates process only the \"blast radius\" of the change, which stays relatively small even as the total graph grows.\n\nAt 10,000 nodes, the full recompute would take over a minute. The incremental update would still be in the low tens of milliseconds. That's the difference between a feature that's practical in production and one that isn't.\n\n## Why the numbers work this way\n\nInputLayer is built on [Differential Dataflow](https://github.com/TimelyDataflow/differential-dataflow), a Rust library for incremental computation created by Frank McSherry. The core idea is simple: instead of storing derived results as static data, the engine represents everything as *differences* that can be efficiently passed along.\n\nHere's how a fact change flows through the system:\n\n```chain\nYou add an edge: \"Diana manages Eve\"\n-- who has authority over Diana?\nEngine finds: Alice and Bob (from existing derivations) [primary]\n-- so they must also have authority over Eve\nEngine checks: does Eve manage anyone? Yes - Frank\n-- so Alice and Bob also get authority over Frank\nEngine checks: does Frank manage anyone? No. Done. [success]\n=> Total work: 4 new derived relationships in ~2ms\n```\n\nThe engine didn't scan the entire graph. It didn't recompute relationships for nodes that weren't affected. It started from the change, followed the ripple effects, and stopped as soon as the ripple died out.\n\nFor recursive reasoning - like transitive authority where conclusions feed back into the computation - the engine runs a loop until it reaches a stable point where no new differences are produced. When something changes later, it re-enters that loop at the point of change and computes only the new differences.\n\nInputLayer also uses a technique called Magic Sets that makes queries demand-driven. When you ask \"who does Alice have authority over?\", the engine doesn't compute authority for every person in the organization. It starts from Alice and follows only the relevant paths. Query time becomes proportional to Alice's portion of the graph, not the entire organization.\n\n## Correct retraction: the hard part\n\nAdding facts is relatively straightforward to handle incrementally. Removing them is where things get genuinely hard.\n\nSay Alice has authority over Charlie through two independent paths:\n\n```flow\nAlice -> Bob -> Charlie [primary]\n```\n\n```flow\nAlice -> Diana -> Charlie [primary]\n```\n\nIf you remove Bob's management of Charlie, Alice should still have authority over Charlie through Diana. But if you remove Diana's management of Charlie too, the authority should disappear entirely.\n\nThe engine tracks this through weighted differences. Each derived relationship has a weight based on the number of independent paths that support it. When a path is removed, the weight goes down. Only when it reaches zero does the conclusion go away.\n\n```steps\nBoth paths exist: authority(Alice, Charlie) weight is 2 :: via Bob and Diana\nRemove Bob to Charlie: weight drops to 1 :: still exists via Diana [success]\nRemove Diana to Charlie: weight drops to 0 :: retracted [highlight]\n```\n\nOn our benchmark graph, retracting a single edge and propagating all downstream changes takes under 10ms. Bulk retractions (removing 100 edges) complete in about a second. Fast enough for real-time applications where facts change frequently.\n\n## What this means in practice\n\nThe practical takeaway here is about which architectural patterns become possible.\n\n**Without incremental computation**, you're stuck with batch processing. Pre-compute permissions overnight. Rebuild recommendation indexes hourly. Re-run compliance checks on a schedule. And accept that between runs, your derived data is stale.\n\n**With incremental computation**, you can do these things live:\n\n| Use case | Batch approach | Incremental approach |\n|---|---|---|\n| Access control | Nightly permission rebuild | Live permission check at query time |\n| Supply chain risk | Hourly risk recalculation | Instant risk update when a supplier status changes |\n| Compliance screening | Daily sanctions check | Real-time flag when ownership structure changes |\n| Recommendations | Model retrain every few hours | Instant update when user behavior or inventory changes |\n\nThe 1,652x speedup isn't about making a slow thing faster. It's about making batch-only workloads work in real time. That's a qualitative difference in what you can build.\n\n## Try it yourself\n\nInputLayer is open-source:\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nStart with the [quickstart guide](/docs/guides/quickstart/) to build your first knowledge graph, or dive into the [recursion documentation](/docs/guides/recursion/) to see how recursive reasoning works under the hood.",toc:[{level:2,text:"The benchmark setup",id:"the-benchmark-setup"},{level:2,text:"The results",id:"the-results"},{level:2,text:"The scaling story",id:"the-scaling-story"},{level:2,text:"Why the numbers work this way",id:"why-the-numbers-work-this-way"},{level:2,text:"Correct retraction: the hard part",id:"correct-retraction-the-hard-part"},{level:2,text:"What this means in practice",id:"what-this-means-in-practice"},{level:2,text:"Try it yourself",id:"try-it-yourself"}]},{slug:"policy-filtered-semantic-search",title:"Policy-Filtered Semantic Search: Access Control Meets Vector Similarity",date:"2026-02-10",author:"InputLayer Team",category:"Architecture",excerpt:"Most systems handle access control and semantic search as separate concerns. Here's what happens when you combine them into a single query.",content:"\n# Policy-Filtered Semantic Search: Access Control Meets Vector Similarity\n\nEvery enterprise RAG application eventually runs into the same problem. The semantic search works great - it finds relevant documents. But then you need to check whether the user is actually allowed to see those documents. And suddenly you're maintaining two systems, writing glue code between them, and dealing with consistency bugs that only show up in production.\n\nThis post is about what happens when you stop treating authorization and retrieval as separate concerns and combine them into a single operation.\n\n## How it usually works (and where it breaks)\n\nThe typical architecture looks like this:\n\n```chain\nUser sends a query\n-- calls auth service\nAuth service returns permissions (e.g. department: \"engineering\", level: \"L5+\")\n-- passes filters to vector database\nVector database runs query with metadata filters\n-- returns results\nFiltered results [success]\n```\n\nThe application calls an auth service to figure out the user's permissions, translates those permissions into metadata filters, and passes those filters to the vector database along with the query. It works. For simple permission models - \"engineering can see engineering docs\" - it works fine.\n\nBut here's where it falls apart. Most real organizations don't have flat permission models. They have hierarchies. And hierarchies are recursive.\n\n## The recursion problem\n\nConsider Sarah, a VP of Engineering at a 500-person company. Her reporting chain looks like this:\n\n```tree\nSarah (VP Engineering) [primary]\n  Marcus (Dir. Platform)\n    Team Alpha (8 people)\n    Team Beta (6 people)\n  Priya (Dir. AI/ML)\n    Team Gamma (10 people)\n    Team Delta (5 people)\n  James (Dir. DevOps)\n    Team Epsilon (7 people)\n```\n\nSarah should be able to see documents from everyone in her org - all 36 people across 5 teams. Marcus should see documents from Alpha and Beta (14 people). A team lead in Alpha should see only Alpha's documents (8 people).\n\nHow do you express \"Sarah can see documents from everyone beneath her in the org chart\" as a metadata filter? You can't hardcode the list of 36 people - that becomes stale the moment someone joins, leaves, or transfers. You can't say `department = \"engineering\"` because that doesn't respect the sub-hierarchies (Marcus shouldn't see Priya's team's confidential documents unless the policy says so).\n\nWhat you actually need is a recursive walk of the reporting structure, starting from Sarah and going down through every layer. And that walk needs to happen at query time, against the current state of the org chart, every single time.\n\nThat's not something a metadata filter can do.\n\n## Combining authorization and search in one pass\n\nIn InputLayer, you describe your org structure as facts (who reports to whom) and your access policy as a rule (managers can see documents from their entire reporting chain). The engine handles both the authorization logic and the semantic search in a single query.\n\nHere's what happens when Sarah searches for \"deployment best practices\":\n\n```steps\nResolve authorization (recursive): start from Sarah, walk her full reporting chain :: Sarah can see docs from 36 people [primary]\nFind documents: filter to documents authored by those 36 people :: 847 documents in scope\nRank by similarity: compare each document's embedding to the query :: Top 10 results, all authorized, ranked by relevance [success]\n```\n\n```note\ntype: tip\nAll three steps happen in one pass. No separate auth service call, no metadata filter translation, no consistency gap.\n```\n\nThe authorization is evaluated against the current state of the org chart, right now, as part of the query.\n\n## The consistency problem most teams don't notice\n\nHere's a subtle bug that exists in nearly every two-system auth+search setup.\n\nMonday: Bob reports to Sarah. Sarah can see Bob's documents. The auth service knows this, the metadata filters reflect it.\n\nTuesday morning: Bob transfers from Engineering to Product. The auth service updates immediately. But the metadata on Bob's documents in the vector database? That gets updated in a batch job that runs at midnight.\n\nTuesday afternoon: Sarah searches for something. The auth service says she can't see Bob's docs anymore (correct). But what about documents authored by someone who reported to Bob, whose metadata filter was set to `org: \"engineering\"` and hasn't been updated yet? That depends on how your metadata propagation works. And these edge cases multiply with every layer of hierarchy and every type of permission grant.\n\n```chain\nBob transfers at 9am\n-- 15-hour consistency gap begins\nAuth says NO, but vector database says YES [highlight]\n-- batch job runs at midnight\nGap finally closes the next day [success]\n```\n\nWith InputLayer, this gap doesn't exist. Authorization is computed from the current facts at query time. Update the reporting structure at 9am, and the 9:01am query reflects the change. No propagation delay, no batch job, no stale permissions.\n\n## It also works in reverse: retraction\n\nWhen Bob leaves the company entirely, you retract the fact that Bob reports to Sarah.\n\nInputLayer automatically retracts everything that was derived through that relationship. Sarah loses access to Bob's documents. She also loses access to documents from anyone who reported through Bob - if Bob managed a team, that entire branch of Sarah's permission tree disappears.\n\nBut here's the important part: if any of those people also report to Sarah through a different path (say, a dotted-line relationship), those permissions survive. The engine tracks how many independent paths support each access grant and only retracts when all paths are gone.\n\nIn an append-only system, Bob's documents just sit there in the index until someone manually cleans them up. In InputLayer, the cleanup is automatic and precise.\n\n## Performance: can you actually do this at query time?\n\nEvaluating a recursive org chart walk on every search request sounds expensive. In practice, it's not.\n\nInputLayer's incremental computation engine means the recursive authorization isn't recomputed from scratch on every query. The first time Sarah queries, the engine walks her reporting chain. After that, it maintains the result incrementally. When the org chart changes, only the affected portion recomputes.\n\n| Operation | Time |\n|---|---|\n| Initial authority computation (2,000-node org) | ~200ms |\n| Incremental update after one org change | <7ms |\n| Subsequent queries (cached derivations) | <1ms for auth + vector search time |\n\nInputLayer also evaluates demand-driven. When Sarah queries, it doesn't compute the authorization chain for every person in the organization. It starts from Sarah and follows only her reporting paths. Query time scales with the size of Sarah's org, not the total company size.\n\nFor a VP with 100 reports (direct and transitive), the authorization adds negligible overhead to the vector search. For a CEO of a 10,000-person company - the most extreme case - it's still in the low tens of milliseconds.\n\n## Getting started\n\nIf you're dealing with authorization that's more complex than flat metadata filters - and most enterprise applications are - this pattern is worth exploring.\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nThe [quickstart guide](/docs/guides/quickstart/) gets you running in about 5 minutes. The [recursion documentation](/docs/guides/recursion/) explains how recursive rules work, which is the foundation for hierarchical authorization.",toc:[{level:2,text:"How it usually works (and where it breaks)",id:"how-it-usually-works-and-where-it-breaks"},{level:2,text:"The recursion problem",id:"the-recursion-problem"},{level:2,text:"Combining authorization and search in one pass",id:"combining-authorization-and-search-in-one-pass"},{level:2,text:"The consistency problem most teams don't notice",id:"the-consistency-problem-most-teams-dont-notice"},{level:2,text:"It also works in reverse: retraction",id:"it-also-works-in-reverse-retraction"},{level:2,text:"Performance: can you actually do this at query time?",id:"performance-can-you-actually-do-this-at-query-time"},{level:2,text:"Getting started",id:"getting-started"}]},{slug:"building-product-recommendation-engine",title:"Building a Product Recommendation Engine with InputLayer",date:"2026-02-05",author:"InputLayer Team",category:"Tutorial",excerpt:"A step-by-step guide to building a recommendation engine that combines collaborative filtering, product relationships, and semantic similarity in a single knowledge graph.",content:'\n# Building a Product Recommendation Engine with InputLayer\n\nA customer just bought a DSLR camera. Your recommendation engine suggests... more cameras. Three other DSLRs in slightly different price ranges.\n\nThe customer doesn\'t need another camera. They need a lens, a memory card, and a bag to carry it all in. But those items look nothing like a camera in embedding space. The connection between "camera" and "camera bag" is *logical* (one is an accessory for the other), not *semantic* (their product descriptions have little overlap).\n\nThis is the gap between similarity-based recommendations and reasoning-based recommendations. In this tutorial, we\'ll build an engine that handles both - and a few other things that traditional recommenders struggle with.\n\n## What we\'re building\n\nBy the end of this tutorial, you\'ll have a recommendation engine with four distinct signals:\n\n```tree\nRecommendation Engine [primary]\n  Collaborative Filtering\n    "users who bought X also bought Y"\n  Category Affinity (recursive)\n    "related product categories, at any depth"\n  Semantic Similarity\n    "products with similar descriptions"\n  Accessory Relationships\n    "this product goes with that one"\n```\n\n```note\ntype: info\nResults are combined, de-duplicated, and filtered: already purchased items are excluded, out-of-stock items are excluded, and discontinued items are removed automatically.\n```\n\nEach signal is expressed as a simple, readable rule. The engine combines them automatically. And because this runs on a knowledge graph with incremental computation, the recommendations stay fresh without model retraining or index rebuilding.\n\n## Step 1: Model your product catalog\n\nEverything starts with your product data. In InputLayer, this means storing structured facts about products, their categories, and how categories relate to each other.\n\nYou store each product with its name and direct category. Then you describe the category hierarchy - running shoes fall under athletic footwear, which falls under footwear, which falls under apparel. This hierarchy is the backbone for one of our recommendation signals.\n\nYou also store embedding vectors for each product, generated from product descriptions using a text embedding model. These power the semantic similarity signal.\n\n```tree\nSports [primary]\n  Athletic\n    Footwear\n      SKU_001 "Running Shoes"\n      SKU_002 "Trail Shoes"\n    Accessories\n      SKU_003 "Running Socks"\n      SKU_004 "Hydration Pack"\n    Electronics\n      SKU_005 "GPS Watch"\n```\n\n## Step 2: Feed in user behavior\n\nNext, purchase history and browsing data. Who bought what, and what have they been looking at recently. In production, you\'d ingest this from your transaction database as events happen.\n\n```tree\nPurchase History\n  user_1: Running Shoes, Running Socks\n  user_2: Running Shoes, Hydration Pack\n  user_3: Trail Shoes, GPS Watch\nBrowsing Data\n  user_1 viewed: Trail Shoes, GPS Watch [muted]\n```\n\nThe important thing: these aren\'t just rows in a table. They\'re facts in a knowledge graph that the reasoning engine can combine with other facts through rules. That\'s the key difference from a traditional recommendation database.\n\n## Step 3: Define recommendation rules\n\nThis is where the approach diverges from traditional ML recommendations. Instead of training a model, we express recommendation logic as rules. Each rule captures a different signal, and each rule is readable in plain English.\n\n**Rule 1 - Collaborative filtering:** "If two users bought the same product, the other products each user bought become recommendations for the other." This is the classic "customers who bought X also bought Y" pattern. But it\'s expressed as a rule, not a matrix factorization - which means you can read it, debug it, and explain exactly why a recommendation appeared.\n\nWhat this looks like in practice for user_1:\n\n```chain\nuser_1 bought Running Shoes\n-- who else bought Running Shoes?\nuser_2 also bought Running Shoes [primary]\n-- what else did user_2 buy?\nuser_2 also bought Hydration Pack\n=> Recommend Hydration Pack to user_1 [success]\n```\n\n**Rule 2 - Category affinity (recursive):** "If a user bought something in one category, recommend products from related categories." This rule is recursive - it follows the category hierarchy to find related categories at any depth.\n\n```chain\nuser_1 bought Running Shoes (in footwear)\n-- walk up the category tree\nFootwear is under Athletic [primary]\n-- what else is under Athletic?\nAccessories and Electronics are also under Athletic\n=> Recommend from related categories: Hydration Pack, GPS Watch [success]\n```\n\nBuying running shoes surfaces recommendations not just from footwear, but from accessories and electronics too, because they share a parent category. And this works no matter how deep or wide your category tree goes.\n\n**Rule 3 - Semantic similarity:** Products with similar descriptions (as measured by their embedding vectors) become recommendations. This catches relationships that the category hierarchy misses - two products from completely different categories that people tend to use together.\n\n**Rule 4 - Accessory relationships:** "When a customer buys a product, recommend its accessories - but only if they haven\'t already bought them and they\'re in stock." This is the explicit knowledge that a camera bag goes with a camera, expressed directly rather than inferred statistically.\n\n## Step 4: Combine and query\n\nNow you ask: "What should we recommend to user_1?"\n\nThe engine evaluates all four rules, combines their results, filters out products user_1 has already bought, checks stock availability, and returns the final list:\n\n```tree\nSignals for user_1 [primary]\n  Collaborative: Hydration Pack (via user_2)\n  Category: Hydration Pack, GPS Watch, Trail Shoes\n  Semantic: Trail Shoes (0.92 similarity to Running Shoes)\n  Accessory: (none defined in this example) [muted]\n```\n\n```steps\nTrail Shoes - matched by category + semantic similarity :: strongest combined signal [primary]\nHydration Pack - matched by collaborative + category :: two independent signals [primary]\nGPS Watch - matched by category :: single signal\n```\n\nEach recommendation carries its provenance. You can explain to the user *why* each item was recommended, and you can explain to your product team which signals are driving the most engagement. Try getting that kind of transparency from a neural collaborative filtering model.\n\n## Step 5: Watch it stay fresh\n\nHere\'s where the knowledge graph approach really shines compared to model-based recommenders.\n\n**A new purchase comes in.** User_1 buys a GPS Watch. You add that fact. All recommendations update instantly - GPS Watch drops out of user_1\'s recommendations (already purchased), and any collaborative filtering signals that involve GPS Watch recalculate. No model retraining needed.\n\n**A product goes out of stock.** You update the stock status for Trail Shoes. Every recommendation that included Trail Shoes disappears from results automatically. When it\'s back in stock, the recommendations come back. No index rebuild needed.\n\n**A product is discontinued.** You retract it from the catalog entirely. InputLayer\'s correct retraction mechanism removes it from every recommendation result, every collaborative filtering signal, every category association - automatically and immediately. No stale suggestions pointing customers to a product page that returns a 404.\n\n```flow\nTraditional ML recommender [highlight] -> Retrain model (hours) -> Rebuild index (minutes) -> Deploy (minutes)\n```\n\n```flow\nInputLayer [success] -> Retract fact -> Recommendations update (~ms) -> Done\n```\n\n## Where to take this next\n\nWhat we\'ve built is the foundation. Here are the layers you\'d add for production:\n\n**Inventory-aware filtering** - only recommend products that are actually in stock and available in the customer\'s region. This is one more condition on the recommendation rule.\n\n**Time decay** - weight recent purchases more heavily than old ones. A customer who bought running shoes yesterday is more likely to need accessories than a customer who bought them two years ago.\n\n**Price affinity** - recommend products in the customer\'s typical price range. If they buy premium products, don\'t recommend budget options.\n\n**Seasonal rules** - boost winter gear in November, swimwear in May. Express seasonality as a rule rather than baking it into a training set.\n\nEach of these is just another rule in the knowledge graph. The engine handles the interactions between all rules automatically - you don\'t need to worry about how time decay interacts with category affinity, or how inventory filtering affects collaborative signals. Define the rules, and the engine composes them.\n\nCheck out the [data modeling guide](/docs/guides/core-concepts/) for patterns that work well at scale, and the [Python SDK](/docs/guides/python-sdk/) for integrating this into your e-commerce platform.',toc:[{level:2,text:"What we're building",id:"what-were-building"},{level:2,text:"Step 1: Model your product catalog",id:"step-1-model-your-product-catalog"},{level:2,text:"Step 2: Feed in user behavior",id:"step-2-feed-in-user-behavior"},{level:2,text:"Step 3: Define recommendation rules",id:"step-3-define-recommendation-rules"},{level:2,text:"Step 4: Combine and query",id:"step-4-combine-and-query"},{level:2,text:"Step 5: Watch it stay fresh",id:"step-5-watch-it-stay-fresh"},{level:2,text:"Where to take this next",id:"where-to-take-this-next"}]},{slug:"why-we-built-on-differential-dataflow",title:"Why We Built InputLayer on Differential Dataflow",date:"2026-01-30",author:"InputLayer Team",category:"Engineering",excerpt:"The story behind our choice of Timely and Differential Dataflow as the computation engine, and what that means for the kinds of problems InputLayer can solve.",content:"\n# Why We Built InputLayer on Differential Dataflow\n\nEvery engineering team has that one decision that shaped everything that came after. For us, it was choosing [Differential Dataflow](https://github.com/TimelyDataflow/differential-dataflow) as the computation engine underneath InputLayer. It determined what we could build, what performance we could offer, and which problems we could solve that other systems can't.\n\nThis is the story of why we made that choice and what it means for the people building on InputLayer today.\n\n## The problem that started everything\n\nWe wanted to build a knowledge graph engine that could do something deceptively simple: keep derived conclusions up to date when facts change.\n\nThat sounds straightforward until you think about scale. Imagine a knowledge graph with 100,000 facts and 50 rules that derive new conclusions from those facts. Some of those rules are recursive - their output feeds back into their input. The initial computation produces millions of derived facts. Fine - that's a one-time cost.\n\nBut then a single fact changes. One employee transfers departments. One entity gets added to a sanctions list. One product goes out of stock.\n\n```chain\n100,000 source facts feed into 50 rules\n-- initial computation\n2,000,000 derived facts [primary]\n-- then one fact changes\nHow many of those 2M derived facts are affected? [highlight]\n=> Usually just a few hundred. But the naive approach recomputes all 2 million.\n```\n\nWith a naive approach, you throw away all 2 million derived facts and recompute them from scratch. For small graphs, that's fast enough. For production workloads, it doesn't work. At 11 seconds per recomputation on a 2,000-node graph, you're locked into batch processing. Real-time permission checks, live compliance screening, instant recommendation updates - none of that is practical.\n\nWe needed an engine that could update just the affected derivations, correctly, in milliseconds.\n\n## What we evaluated\n\nWe spent months evaluating different approaches. Each one taught us something about what we needed.\n\n**Batch-oriented engines** are the gold standard for one-time rule evaluation. They compile rules into extremely efficient programs that process an entire dataset in one pass. Some even generate low-level code that runs blazingly fast for batch workloads.\n\nThe limitation: there's no concept of \"update.\" If you add a fact, you rerun the entire program. For a knowledge graph that changes frequently - which is most production use cases - that means paying the full computation cost every time anything changes.\n\n**Graph databases** offer incremental capabilities for simple path queries. But their query languages weren't designed for recursive derivation. They can traverse stored edges, but they can't derive *new* edges based on rules and then recursively reason over those derived edges. And they don't maintain results incrementally when the graph changes.\n\n**Building from scratch** was tempting. We could design an incremental engine perfectly suited to our needs. But correct incremental maintenance through recursive fixpoints is one of the hardest problems in database research. Tracking which derived facts should retract when a source fact is removed - especially when derived facts might have multiple supporting paths - is notoriously subtle. Teams that have tried typically spend years before reaching production quality.\n\n```tree\nWhat we needed [primary]\n  Fast batch computation\n  Incremental updates (not full recompute)\n  Recursive derivation (rules that reference themselves)\n  Correct retraction (delete actually deletes)\n  Reasonable time to production\n```\n\n```note\ntype: warning\nNo single existing approach gave us everything we needed. Batch engines lacked incremental updates. Graph databases lacked recursive derivation. Building from scratch would take years.\n```\n\n## Finding Differential Dataflow\n\nThen we found Frank McSherry's work on [Differential Dataflow](https://github.com/TimelyDataflow/differential-dataflow), built on top of [Timely Dataflow](https://github.com/TimelyDataflow/timely-dataflow). Both are Rust libraries. The performance was a bonus. The computational model was the real discovery.\n\nThe core idea is simple enough to explain in a paragraph: instead of storing derived data as static results, the engine represents everything as *weighted differences*. Adding a fact is a +1 difference. Removing a fact is a -1 difference. Every computation in the system processes differences in and produces differences out. This means every operation is naturally incremental - it never looks at the whole dataset, only at what changed.\n\n```flow\nTraditional: Input facts -> Compute ALL -> Static results\n```\n\n```flow\nAfter change (traditional): Changed fact -> Compute ALL again [highlight] -> Rebuilt results\n```\n\n```flow\nDifferential: Changed fact -> Compute DIFFERENCE only [success] -> Only changed derivations\n```\n\n## How it handles the hard part: recursive retraction\n\nThe real test of an incremental system isn't additions - it's deletions. And specifically, deletions through recursive derivation chains.\n\nHere's the scenario that breaks naive incremental systems. Alice has authority over Charlie through two independent paths:\n\n```flow\nPath 1: Alice -> Bob -> Charlie [primary]\n```\n\n```flow\nPath 2: Alice -> Diana -> Charlie [primary]\n```\n\nRemove Bob's management of Charlie. Does Alice lose authority over Charlie? *No* - the path through Diana still supports it. Now remove Diana's management of Charlie too. Does Alice lose authority over Charlie? *Yes* - there are no remaining paths.\n\nDifferential Dataflow handles this through its weight-based model. Each derived fact carries a weight representing the number of independent derivation paths. Removing a path decreases the weight. The fact only retracts when the weight hits zero.\n\n```steps\nBoth paths exist: authority(Alice, Charlie) weight is 2 :: Alive\nRemove Bob's path: weight drops to 1 :: Still alive - Diana's path remains [success]\nRemove Diana's path: weight drops to 0 :: Retracted [highlight]\n```\n\nThis sounds simple in theory. In practice, getting it right through multiple levels of recursive derivation, where intermediate conclusions can also have multiple support paths, is extraordinarily difficult. Differential Dataflow solves it at the engine level, which means we didn't have to.\n\n## What this gives InputLayer users\n\nBuilding on Differential Dataflow gave us three properties that show up directly in what you can build with InputLayer.\n\n**Incremental maintenance:** When a fact changes, only the affected derivations recompute. On a 2,000-node graph with 400,000 derived relationships, updating a single edge takes 6.83ms instead of 11.3 seconds. That's a 1,652x speedup that turns batch-only workloads into real-time operations.\n\n**Correct retraction:** Delete a fact, and everything derived through it disappears - but only if there's no alternative derivation path. Phantom permissions, stale recommendations, lingering compliance flags - these bugs simply don't exist when the engine handles retraction correctly.\n\n**Demand-driven evaluation:** We combined Differential Dataflow with Magic Sets optimization, which rewrites recursive rules to only compute what's needed for a specific query. Ask \"who does Alice have authority over?\" and the engine starts from Alice and follows only her paths - it doesn't compute authority for the entire organization. Query time is proportional to the relevant portion of the graph.\n\n## The tradeoffs\n\nNo engineering decision is free. Here's what we trade.\n\n**Memory:** Differential Dataflow maintains operator state in memory. For very large datasets, memory usage grows with the size of the maintained derivations. We handle this with persistent storage - Parquet files plus a write-ahead log - that lets us recover state without keeping everything in memory indefinitely. But it's a real consideration for very large knowledge graphs.\n\n**Complexity floor:** The Timely/Differential Dataflow programming model is powerful but has a steep learning curve. We invested significant engineering time building the abstraction layer that compiles high-level rules into efficient dataflow graphs. Users never touch the dataflow layer directly - but we do, and it required deep expertise to get right.\n\n**Single-node:** Currently, InputLayer runs on a single node. Timely Dataflow supports distributed computation, and that's on our roadmap. But today, the engine is bounded by what a single machine can handle. For most knowledge graph workloads, that's millions of facts and derived relationships - but it's a real limit for truly massive datasets.\n\n## Where the choice matters most\n\nThe Differential Dataflow foundation matters most for use cases where data changes frequently and derived conclusions need to stay current. Access control hierarchies where people change roles regularly. Supply chain graphs where supplier status changes daily. Compliance systems where entity relationships and sanctions lists are updated constantly. Agent memory systems where new observations arrive continuously.\n\nFor batch-once-query-many workloads with no updates, a simpler engine would be fine. But the moment your facts change and you need derived conclusions to stay correct, the incremental approach pays for itself immediately.\n\nOur [benchmarks post](/blog/benchmarks-1587x-faster-recursive-queries/) has the specific numbers. And the [quickstart guide](/docs/guides/quickstart/) gets you running in about 5 minutes so you can see it in action.",toc:[{level:2,text:"The problem that started everything",id:"the-problem-that-started-everything"},{level:2,text:"What we evaluated",id:"what-we-evaluated"},{level:2,text:"Finding Differential Dataflow",id:"finding-differential-dataflow"},{level:2,text:"How it handles the hard part: recursive retraction",id:"how-it-handles-the-hard-part-recursive-retraction"},{level:2,text:"What this gives InputLayer users",id:"what-this-gives-inputlayer-users"},{level:2,text:"The tradeoffs",id:"the-tradeoffs"},{level:2,text:"Where the choice matters most",id:"where-the-choice-matters-most"}]},{slug:"fraud-detection-entity-chain-reasoning",title:"Fraud Detection Through Entity Chain Reasoning",date:"2026-01-25",author:"InputLayer Team",category:"Use Case",excerpt:"How knowledge graph reasoning uncovers fraud that pattern matching misses - by following chains of entity relationships across corporate structures and transaction flows.",content:"\n# Fraud Detection Through Entity Chain Reasoning\n\nHere's a transaction your screening system flagged as clean: a wire transfer from your client to Alpha Corp for $50,000. Alpha Corp is a registered corporation with a clean record. Nothing suspicious.\n\nExcept Alpha Corp is a subsidiary of Beta LLC. Beta LLC is 60% owned by Gamma Holding. And Gamma Holding is 80% controlled by someone on a sanctions list.\n\n```chain\nYour client sends $50K to Alpha Corp\n-- subsidiary of\nBeta LLC\n-- 60% owned by\nGamma Holding\n-- 80% owned by\nSANCTIONED ENTITY [highlight]\n=> Four hops deep. Each record looks clean in isolation. The violation is only visible through the chain.\n```\n\nTraditional fraud detection systems check the direct counterparty against a list. That catches the obvious cases. It completely misses the layered structures that sophisticated actors actually use.\n\n## Why pattern matching can't solve this\n\nMost fraud detection runs on rules over individual transactions. Flag transactions over $10,000. Flag transactions to high-risk jurisdictions. Flag counterparties that appear on sanctions lists. These rules work on a per-transaction basis, looking at fields on a single record.\n\nThe structural fraud problem is fundamentally different. You're not looking for a suspicious field on a single transaction. You're looking for a suspicious *path* through a network of entity relationships - a path that might not exist in any single system.\n\n```tree\nWhat pattern matching sees [muted]\n  Transaction #TX-001\n    From: Our Client\n    To: Alpha Corp\n    Amount: $50,000\n    Sanctions match: NO\n    PEP match: NO\n    High-risk jurisdiction: NO\n```\n\n```tree\nWhat chain reasoning sees [highlight]\n  Alpha Corp\n    subsidiary of Beta LLC\n      60% owned by Gamma Holding\n        80% owned by SANCTIONED PERSON\n  Indirect sanctions exposure: YES\n```\n\nThe information exists across separate registries - corporate records, ownership filings, sanctions lists. No single database contains the complete picture. You have to follow the chain.\n\n## How InputLayer traces these chains\n\nIn InputLayer, you model entity relationships as facts: \"Person X owns 80% of Company Y.\" \"Company A is a subsidiary of Company B.\" These facts come from corporate registries, ownership databases, and KYC records - data you probably already collect.\n\nThen you define the compliance logic as a rule: \"An entity has sanctions exposure if it's directly sanctioned, or if it's owned (above a threshold) by an entity that has sanctions exposure.\"\n\nThat second clause is recursive. It says: trace the ownership chain as deep as it goes, and at every level, check whether the owner has sanctions exposure. If the owner does - whether directly or through its own ownership chain - the exposure flows down.\n\nHere's what the engine does when it evaluates this rule against our example:\n\n```steps\nIs Alpha Corp directly sanctioned? No. :: Check direct status\nWho owns Alpha Corp? Beta LLC (subsidiary). :: Walk up one level\nIs Beta LLC directly sanctioned? No. :: Check direct status\nWho owns Beta LLC? Gamma Holding (60%, above 25% threshold). :: Walk up one level\nIs Gamma Holding directly sanctioned? No. :: Check direct status\nWho owns Gamma Holding? Sanctioned Person (80%, above 25% threshold). :: Walk up one level\nIs Sanctioned Person directly sanctioned? YES. :: Match found [highlight]\n```\n\n```chain\nSanctioned Person is sanctioned\n-- exposure flows down through ownership\nGamma Holding has indirect sanctions exposure [highlight]\n-- exposure flows down\nBeta LLC has indirect sanctions exposure [highlight]\n-- exposure flows down\nAlpha Corp has indirect sanctions exposure [highlight]\n=> Transaction TX-001 is FLAGGED\n```\n\nThe engine didn't just check the direct counterparty. It walked the full ownership and control chain, evaluated the sanctions exposure rule at every level, and passed the result back down. All automatically, from a single rule definition.\n\nAnd this works for chains of any depth. Five layers of shell companies? No problem. Ten intermediaries? The engine follows the chain until there's nowhere left to go.\n\n## Beneficial ownership: the same pattern, different question\n\nRegulators worldwide are tightening beneficial ownership requirements. The core question is: who are the natural persons that ultimately own or control this entity?\n\nThe computation is surprisingly similar to sanctions screening, with one twist: you need to multiply ownership percentages through the layers.\n\n```flow\nPerson X (80%) -> Holding A (60%) -> Company B [primary]\n```\n\nEffective beneficial ownership of Person X in Company B: 80% x 60% = 48%. If your regulatory threshold is 25%, Person X is a beneficial owner of Company B even though they don't own it directly.\n\nAdd more layers, and the math compounds:\n\n```flow\nPerson X (80%) -> Holding A (60%) -> Sub B (70%) -> Company C [primary]\n```\n\nEffective ownership: 80% x 60% x 70% = 33.6%. Still above 25% - Person X is a beneficial owner of Company C.\n\nInputLayer handles the multiplication and propagation through any number of layers. Define a threshold, and the engine identifies every natural person who qualifies as a beneficial owner for every entity in your graph.\n\n## What happens when facts change\n\nThis is where the knowledge graph approach becomes especially valuable for compliance. Entity relationships change constantly. Companies are acquired. Ownership stakes are transferred. New sanctions designations are published. Old ones are lifted.\n\nWhen you add a new sanctions designation - say Gamma Holding's owner gets added to the list - InputLayer propagates the change immediately. It identifies every entity in that person's ownership chain, evaluates whether the ownership thresholds are met, and flags the affected transactions. On a graph with thousands of entities, this takes milliseconds.\n\n```flow\nBefore (batch): Sanctions list updated [highlight] -> Full recomputation (seconds to minutes) -> Alerts are stale until done\n```\n\n```flow\nWith InputLayer: Sanctions list updated [success] -> Incremental update (milliseconds) -> Alerts are current immediately\n```\n\nThe reverse is equally important. When someone is removed from a sanctions list, all the downstream flags that were derived through their ownership chain clear automatically. No manual cleanup, no stale alerts clogging up your compliance team's queue. And if an entity had sanctions exposure through *multiple* paths (e.g., owned by two sanctioned individuals), removing one designation correctly preserves the remaining exposure.\n\n## Structuring detection: connecting related entities\n\nBeyond direct sanctions, compliance teams need to detect structuring - splitting large transactions into smaller ones to avoid reporting thresholds. The standard approach checks individual transactions against the $10,000 threshold. Sophisticated actors split transactions across related entities to stay below it.\n\n```tree\nSanctioned Person [highlight]\n  Entity A\n  Entity B\n  Entity C\n```\n\n```chain\nEntity A sends $4,000 to Target Company\n-- related entity\nEntity B sends $3,500 to Target Company\n-- related entity\nEntity C sends $3,000 to Target Company\n=> Combined total: $10,500 - above threshold [highlight]\n```\n\nEach individual transaction is below $10,000. But the entities are related through common ownership, and their combined transactions to the same target exceed the threshold.\n\nInputLayer's recursive reasoning identifies these relationships automatically. It determines which entities are connected through any chain of ownership, aggregates their transactions within a time window, and fires an alert when the combined total exceeds the threshold. The \"related entity\" determination is itself a recursive walk - Entity A and Entity C might be connected through multiple intermediate layers.\n\n## Getting started\n\nIf you're working on compliance, sanctions screening, or transaction monitoring, this approach to entity chain reasoning is worth exploring.\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nThe [quickstart guide](/docs/guides/quickstart/) gets you running in about 5 minutes. The [recursion documentation](/docs/guides/recursion/) covers the recursive reasoning that powers entity chain traversal.",toc:[{level:2,text:"Why pattern matching can't solve this",id:"why-pattern-matching-cant-solve-this"},{level:2,text:"How InputLayer traces these chains",id:"how-inputlayer-traces-these-chains"},{level:2,text:"Beneficial ownership: the same pattern, different question",id:"beneficial-ownership-the-same-pattern-different-question"},{level:2,text:"What happens when facts change",id:"what-happens-when-facts-change"},{level:2,text:"Structuring detection: connecting related entities",id:"structuring-detection-connecting-related-entities"},{level:2,text:"Getting started",id:"getting-started"}]},{slug:"when-similarity-is-not-enough",title:"InputLayer + Your Vector Database: When Similarity Is Not Enough",date:"2026-01-20",author:"InputLayer Team",category:"Architecture",excerpt:"Your vector database handles similarity search beautifully. But some queries need reasoning, not just retrieval. Here's how to know when you need both.",content:"\n# InputLayer + Your Vector Database: When Similarity Is Not Enough\n\nYour vector database is probably doing exactly what you need it to do. Embed documents, search by similarity, feed context to your LLM. For a lot of use cases, that pipeline works beautifully and you shouldn't change it.\n\nBut at some point - maybe you've already hit it - you'll encounter queries where the results are *relevant* but not *correct*. The returned documents are genuinely similar to the query. They just don't answer the actual question, because the answer requires connecting dots that no similarity metric can connect.\n\nThis post is about recognizing that moment and understanding what to do about it.\n\n## A tale of two questions\n\nHere's the clearest way to see the difference. Consider two questions a financial analyst might ask:\n\n**Question A:** \"Show me recent reports about risk management.\"\n\nThis is a similarity question. The answer is a set of documents whose content is semantically close to \"risk management.\" Your vector database handles this perfectly. Embed the query, find nearest neighbors, done.\n\n**Question B:** \"Does our client have exposure to any sanctioned entities?\"\n\nThis is a reasoning question. The answer requires tracing ownership chains through corporate structures - Entity A owns 60% of Entity B, which has a subsidiary C, which is on a sanctions list. No single document contains this answer. The information is spread across entity registrations, ownership records, and sanctions lists.\n\n```flow\nQuestion A: similarity search [success] -> Relevant documents found\n```\n\n```chain\nQuestion B: similarity search\n-- finds documents that mention sanctions\nBut that's not the same as HAVING exposure [highlight]\n-- needs reasoning instead\nTrace ownership chain through entity relationships\n=> Yes or No answer (from connected facts, not document similarity) [success]\n```\n\nYour vector database will find documents that *mention* sanctions for Question B. It might even find documents about your client. But it can't trace the ownership chain that connects them. That connection is structural, not semantic.\n\n## Three signs you've hit the wall\n\nOver time, we've noticed three patterns that signal teams need reasoning alongside their retrieval.\n\n### 1. You're writing multi-query orchestration code\n\nThe first sign is architectural. You find yourself writing application code that makes multiple database calls and stitches the results together. Query the vector database for relevant docs. Query a graph for relationships. Hit an auth service. Reconcile everything in application code.\n\n```\n// This code smell means you need a reasoning layer\nconst docs = await vectorDB.search(queryEmbedding, topK=50);\nconst userPerms = await authService.getPermissions(userId);\nconst filteredDocs = docs.filter(d =>\n  userPerms.departments.includes(d.metadata.department) ||\n  userPerms.teams.includes(d.metadata.team) ||\n  (d.metadata.author && await orgChart.isSubordinate(d.metadata.author, userId))\n);\n// ^ This recursive check is the red flag\n```\n\nThe recursive `isSubordinate` check at the end is the tell. You've hit a reasoning problem and you're trying to solve it with imperative code and API calls. It works, but it's fragile, slow, and hard to keep consistent.\n\n### 2. Your metadata filters can't express the access policy\n\nThis is the access control version. Your permission model started simple - department-based, maybe role-based. But now it involves hierarchies: managers can see their reports' documents, and their reports' reports, and so on down the chain.\n\n```chain\nSimple access control (works fine)\n-- metadata filter\nFilter: department = \"engineering\" [success]\n```\n\n```chain\nComplex access control (breaks down)\n-- metadata filter\nFilter: author in ??? [highlight]\n-- you don't know the list\nYou need to recursively traverse the org chart first\n=> Can't express \"everyone in Alice's reporting chain\" as a flat filter\n```\n\nYou can't express \"everyone in Alice's transitive reporting chain\" as a flat metadata filter because you don't know who's in that chain until you recursively traverse the org chart. And that chain changes every time someone joins, leaves, or transfers.\n\n### 3. Stale derived data is accumulating silently\n\nThe third sign is the most sneaky because it's invisible at first. Your system has derived some conclusions - cached recommendations, pre-computed access lists, materialized views - and the source data has changed, but the conclusions haven't updated.\n\nA partner relationship ended three months ago. The partnership flag was removed from the CRM. But the integration recommendations, the priority support routing, the shared document access - those derived conclusions are still sitting in various caches and indexes. Nobody cleaned them up because nobody knows all the places they spread to.\n\n```tree\nFact: Partner relationship ended (March) [highlight]\n  Still in vector index: \"Company X gets priority support\" (from April doc) [muted]\n  Still in recommendations: \"Try Company X's integration\" (stale since March) [muted]\n  Still in access list: Company X employees see partner docs (stale since March) [muted]\n```\n\n```note\ntype: warning\nIn InputLayer, retracting the partnership fact automatically retracts every conclusion derived from it. In a system without proper retraction, these stale conclusions accumulate month after month.\n```\n\n## How the two systems complement each other\n\nThe mental model is simple:\n\n```flow\nYour vector database [primary] -> \"What content looks most like this query?\"\n```\n\n```flow\nInputLayer [primary] -> \"What can be concluded from these facts and rules?\"\n```\n\nMost real applications need both. A customer support agent needs to find relevant help articles (vector search) and check the customer's subscription tier (reasoning). A research assistant needs to find related papers (vector search) and trace the citation graph to foundational work (graph reasoning). A financial advisor needs to find matching investment products (vector search) and verify regulatory compliance (rule evaluation).\n\nThe cleanest pattern is straightforward: use each system for what it's best at. Keep your vector database for similarity queries. Add InputLayer for the reasoning queries. For the cases where you need both at the same time - \"find documents similar to X that this user is authorized to see through their reporting chain\" - InputLayer handles the combined query in a single pass with its native vector search capabilities.\n\n## When to stick with just your vector database\n\nNot every application needs reasoning. If your queries are straightforward similarity lookups with simple metadata filters, your vector database is the right tool and adding InputLayer would be unnecessary complexity.\n\nThe honest assessment: if you don't have any of the three signs above - no multi-query orchestration, no hierarchical access control, no stale derived data - you probably don't need InputLayer yet. And that's fine. Build with what works today and add the reasoning layer when you actually need it.\n\nThe trigger is when you find yourself building a reasoning engine inside your application code. When that happens, you're better off using one that's purpose-built.\n\n## Getting started\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```\n\nThe [quickstart guide](/docs/guides/quickstart/) takes about 5 minutes. If you're specifically interested in combining vector search with reasoning, the [vectors documentation](/docs/guides/vectors/) covers InputLayer's native vector capabilities.",toc:[{level:2,text:"A tale of two questions",id:"a-tale-of-two-questions"},{level:2,text:"Three signs you've hit the wall",id:"three-signs-youve-hit-the-wall"},{level:3,text:"1. You're writing multi-query orchestration code",id:"1-youre-writing-multi-query-orchestration-code"},{level:3,text:"2. Your metadata filters can't express the access policy",id:"2-your-metadata-filters-cant-express-the-access-policy"},{level:3,text:"3. Stale derived data is accumulating silently",id:"3-stale-derived-data-is-accumulating-silently"},{level:2,text:"How the two systems complement each other",id:"how-the-two-systems-complement-each-other"},{level:2,text:"When to stick with just your vector database",id:"when-to-stick-with-just-your-vector-database"},{level:2,text:"Getting started",id:"getting-started"}]},{slug:"correct-retraction-why-delete-should-actually-delete",title:"Correct Retraction: Why Delete Should Actually Delete",date:"2026-01-15",author:"InputLayer Team",category:"Engineering",excerpt:"When you delete a fact from a knowledge graph, what happens to everything that was derived from it? Most systems get this wrong. Here's why it matters and how InputLayer handles it.",content:"\n# Correct Retraction: Why Delete Should Actually Delete\n\nThree months after a security incident, the forensics team discovers something troubling. A former employee - let's call him Bob - had his access revoked on the day he left. His account was deactivated. His role was removed from the auth system.\n\nBut Bob had authority over a team of six people. Those six people had authored documents. The system had derived that Bob's manager, Alice, could access those documents through Bob. When Bob left, his direct access disappeared. But Alice's transitive access to those documents - the part that was *derived* through Bob's position - was never cleaned up.\n\nFor three months, Alice had access to documents she shouldn't have been able to see. Not because anyone made an error, but because the system didn't properly retract derived conclusions when a source fact was removed.\n\nThis is the correct retraction problem. And it's one of the most under-appreciated issues in data systems that derive conclusions from connected facts.\n\n## Simple on the surface, hard underneath\n\nAt first glance, retraction seems trivial. Delete a fact, delete everything that depended on it. Done.\n\nLet's walk through why it's not that simple.\n\nAlice manages Bob. Bob manages Charlie. The system derives transitive authority:\n\n```tree\nAlice [primary]\n  Bob (direct report)\n    Charlie (Bob's direct report)\n```\n\n```steps\nAlice has authority over Bob :: direct\nBob has authority over Charlie :: direct\nAlice has authority over Charlie :: transitive: Alice to Bob to Charlie\n```\n\nBob leaves the company. You remove \"Alice manages Bob.\" What should happen?\n\n```steps\nAlice has authority over Bob :: RETRACT - no longer manages him [highlight]\nAlice has authority over Charlie :: RETRACT - was derived through Bob [highlight]\nBob has authority over Charlie :: KEEP - this fact is independent of Alice [success]\n```\n\nAlice loses authority over both Bob and Charlie. But Bob keeps authority over Charlie because that relationship doesn't depend on Alice's management of Bob. The retraction needs to be precise - it can't just cascade blindly down the graph.\n\nOK, that's manageable. But now consider the harder case.\n\n## The diamond problem\n\nAlice manages both Bob and Diana. Both Bob and Diana manage Charlie.\n\n```tree\nAlice [primary]\n  Bob\n    Charlie\n  Diana\n    Charlie\n```\n\nAlice has authority over Charlie through *two independent paths*: through Bob and through Diana. The derived fact `authority(Alice, Charlie)` has two reasons to exist.\n\nNow Bob stops managing Charlie:\n\n```tree\nAlice [primary]\n  Bob [muted]\n  Diana\n    Charlie [success]\n```\n\nShould Alice lose authority over Charlie? **No.** The path through Diana still supports it.\n\nNow Diana also stops managing Charlie:\n\n```tree\nAlice [primary]\n  Bob [muted]\n  Diana [muted]\nCharlie (no paths remain) [highlight]\n```\n\n*Now* Alice should lose authority over Charlie. Both supporting paths are gone.\n\nThis is the multiple derivation path problem, and it's what makes correct retraction genuinely difficult. A derived conclusion should only disappear when *every* path that supports it has been removed. Not when the first path is removed. Not when most paths are removed. Only when the count reaches zero.\n\n## How most systems get this wrong\n\nThere are three common approaches, and each fails in a different way.\n\n**Approach 1: Don't retract derived data at all.** Many systems are append-only for derived conclusions. You can mark a source fact as deleted, but the derived facts remain in whatever cache, index, or materialized view they were written to. This is the \"phantom permissions\" problem - users retain access that should have been revoked. It's also the \"ghost recommendations\" problem - discontinued products keep showing up because the derived recommendation was never cleaned up.\n\n**Approach 2: Recompute everything from scratch.** Throw away all derived data and re-derive it all. This is correct but expensive. On a knowledge graph with millions of derived facts, recomputation takes seconds or minutes. You can run it as a batch job, but between batch runs, your data is potentially inconsistent.\n\n**Approach 3: Delete derived facts that \"look related.\"** Walk from the retracted fact and delete anything downstream. This is fast, but it's wrong whenever the diamond problem appears. You'll delete conclusions that should have survived because they had alternative derivation paths.\n\n```tree\nApproaches compared [primary]\n  Append-only (no retraction)\n    Simple retraction: No [highlight]\n    Diamond problem: No [highlight]\n    Performance: N/A [muted]\n  Full recomputation\n    Simple retraction: Yes [success]\n    Diamond problem: Yes [success]\n    Performance: Slow (seconds to minutes) [highlight]\n  Naive cascade deletion\n    Simple retraction: Yes [success]\n    Diamond problem: No (deletes too much) [highlight]\n    Performance: Fast but incorrect [highlight]\n  Weighted differences (InputLayer)\n    Simple retraction: Yes [success]\n    Diamond problem: Yes [success]\n    Performance: Fast and correct [success]\n```\n\n## How InputLayer solves it: weighted differences\n\nInputLayer is built on Differential Dataflow, which represents every derived fact as a weighted record. The weight counts the number of independent derivation paths that support the conclusion.\n\nHere's the diamond example, step by step:\n\n```steps\nInitial state: Alice manages Bob and Diana, both manage Charlie :: authority(Alice, Charlie) has weight 2\nRemove \"Bob manages Charlie\": -1 via Bob path :: Weight is now 1 - conclusion SURVIVES [success]\nRemove \"Diana manages Charlie\": -1 via Diana path :: Weight is now 0 - conclusion RETRACTED [highlight]\n```\n\nThe engine doesn't need to search for alternative paths or do any special-case reasoning. The weight arithmetic handles it automatically. And this works through any number of recursive levels - if the derivation chain is 10 hops deep with branching paths at every level, the weights still track correctly.\n\n## Retraction through recursive chains\n\nThe diamond problem is hard enough with a single level of derivation. With recursion, it gets harder - but the weighted approach still handles it.\n\nConsider a deeper hierarchy:\n\n```flow\nAlice -> Bob -> Charlie -> Diana -> Eve [primary]\n```\n\nThe derived fact `authority(Alice, Eve)` goes through 4 hops. If you remove \"Charlie manages Diana,\" the engine needs to retract not just `authority(Charlie, Diana)` but also `authority(Alice, Diana)`, `authority(Bob, Diana)`, `authority(Alice, Eve)`, `authority(Bob, Eve)`, and `authority(Charlie, Eve)` - every derived authority that passed through the Charlie-Diana link.\n\nBut if Diana also reports to someone else (say, Frank, who reports to Alice through a different branch), some of those authority relationships might survive through the alternative path.\n\nThe engine tracks all of this through differences. Each removal spreads as a -1 difference through the derivation graph. At each node, the difference combines with existing weights. Conclusions retract when and only when their weight reaches zero. No manual reasoning about paths needed.\n\n## Why this matters: three real scenarios\n\n**Access control:** When someone leaves the company, every permission derived through their position needs to disappear. But only the permissions that were *exclusively* derived through their position. If a document was accessible through two independent authorization paths and one is removed, access should continue through the remaining path. Getting this wrong means either phantom permissions (security risk) or over-retraction (broken access for people who should still have it).\n\n**Recommendations:** When a product is discontinued, every recommendation that included it should vanish. If a recommendation was \"users who bought X also bought Y,\" and Y is discontinued, the recommendation disappears. But if Y was also recommended through a different signal (semantic similarity, category affinity), that recommendation should survive through the remaining signal.\n\n**Compliance:** When an entity is removed from a sanctions list, every downstream flag derived from that designation should clear. But if an entity had sanctions exposure through two different ownership paths, removing one designation should correctly preserve the remaining exposure. Your compliance team should not be chasing alerts that are no longer valid. They should also not miss alerts that are still valid because the retraction was too aggressive.\n\n## Performance\n\nCorrect retraction is only useful if it's fast enough to happen in real time. If propagating a retraction takes seconds, you're back to batch processing.\n\n| Operation | Time (2,000-node graph) |\n|---|---|\n| Retract 1 edge, propagate all downstream changes | <10ms |\n| Retract 10 edges, propagate all downstream changes | ~100ms |\n| Retract 100 edges, propagate all downstream changes | ~1 second |\n\nThese numbers come from our benchmark graph with ~400,000 derived relationships. The incremental approach means each retraction only touches the affected portion of the derivation graph. The total graph size barely matters - what matters is the size of the ripple effect from the specific retraction.\n\n## Getting started\n\nIf you want to see correct retraction in action, the [quickstart guide](/docs/guides/quickstart/) walks through a hands-on example. The [recursion documentation](/docs/guides/recursion/) explains how recursive rules interact with retraction. And our [benchmarks post](/blog/benchmarks-1587x-faster-recursive-queries/) covers the performance characteristics in detail.\n\n```bash\ndocker run -p 8080:8080 ghcr.io/inputlayer/inputlayer\n```",toc:[{level:2,text:"Simple on the surface, hard underneath",id:"simple-on-the-surface-hard-underneath"},{level:2,text:"The diamond problem",id:"the-diamond-problem"},{level:2,text:"How most systems get this wrong",id:"how-most-systems-get-this-wrong"},{level:2,text:"How InputLayer solves it: weighted differences",id:"how-inputlayer-solves-it-weighted-differences"},{level:2,text:"Retraction through recursive chains",id:"retraction-through-recursive-chains"},{level:2,text:"Why this matters: three real scenarios",id:"why-this-matters-three-real-scenarios"},{level:2,text:"Performance",id:"performance"},{level:2,text:"Getting started",id:"getting-started"}]}];var u=n(8340);let m=(0,u.A)("Check",[["path",{d:"M20 6 9 17l-5-5",key:"1gmf2c"}]]),p=(0,u.A)("Copy",[["rect",{width:"14",height:"14",x:"8",y:"8",rx:"2",ry:"2",key:"17jyea"}],["path",{d:"M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2",key:"zix9uf"}]]),g=(0,u.A)("CircleCheckBig",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]]),y=(0,u.A)("Minus",[["path",{d:"M5 12h14",key:"1ays0h"}]]),f=(0,u.A)("CircleX",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["path",{d:"m15 9-6 6",key:"1uzhvr"}],["path",{d:"m9 9 6 6",key:"z0biqf"}]]),b=(0,u.A)("Database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]]);var v=n(718);let x=(0,u.A)("Zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]]);var w=n(1628),k=n(4290),j=n(2164),N=n(439);let A=(0,u.A)("GitBranch",[["line",{x1:"6",x2:"6",y1:"3",y2:"15",key:"17qcm7"}],["circle",{cx:"18",cy:"6",r:"3",key:"1h7g24"}],["circle",{cx:"6",cy:"18",r:"3",key:"fqmcym"}],["path",{d:"M18 9a9 9 0 0 1-9 9",key:"n2h4wq"}]]),T=`// Facts: who manages whom
+manages("alice", "bob")
+manages("bob", "charlie")
+manages("bob", "diana")

// Rule: transitive authority (recursive)
+authority(X, Y) <- manages(X, Y)
+authority(X, Z) <- manages(X, Y), authority(Y, Z)

// Query: who does Alice have authority over?
?authority("alice", Person)`,S=`// Policy-filtered semantic search - one query
?authority("alice", Author),
 document(DocId, Author, Embedding),
 Similarity = cosine(Embedding, QueryVec),
 Similarity > 0.7`;function I({text:e}){let[t,n]=(0,i.useState)(!1);return(0,a.jsx)("button",{onClick:()=>{navigator.clipboard.writeText(e),n(!0),setTimeout(()=>n(!1),2e3)},className:"absolute top-3 right-3 inline-flex items-center gap-1.5 rounded-md border border-border bg-background/80 px-2.5 py-1.5 text-xs text-muted-foreground backdrop-blur transition-colors hover:text-foreground hover:bg-background",children:t?(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(m,{className:"h-3.5 w-3.5 text-emerald-500"}),"Copied"]}):(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(p,{className:"h-3.5 w-3.5"}),"Copy"]})})}function C({code:e,className:t}){let n=(0,h.nW)(e);return(0,a.jsx)("pre",{className:`rounded-lg bg-[var(--code-bg)] p-4 overflow-x-auto text-sm font-mono ${t??""}`,children:(0,a.jsx)("code",{dangerouslySetInnerHTML:{__html:n}})})}function B({children:e}){return(0,a.jsx)("span",{className:"inline-flex items-center rounded-full border border-border bg-secondary/50 px-3 py-1 text-sm text-secondary-foreground",children:e})}function D({value:e}){switch(e){case"native":return(0,a.jsx)(g,{className:"h-4 w-4 text-emerald-500"});case"plugin":return(0,a.jsx)(g,{className:"h-4 w-4 text-yellow-500"});case"partial":return(0,a.jsx)(y,{className:"h-4 w-4 text-yellow-500"});case"none":return(0,a.jsx)(f,{className:"h-4 w-4 text-muted-foreground/40"})}}function q(){return(0,a.jsxs)("div",{className:"flex flex-col min-h-dvh",children:[(0,a.jsx)(o.D,{}),(0,a.jsxs)("section",{className:"relative overflow-hidden border-b border-border/50",children:[(0,a.jsx)("div",{className:"absolute inset-0 bg-gradient-to-b from-primary/5 to-transparent"}),(0,a.jsx)("div",{className:"relative mx-auto max-w-6xl px-6 py-24 lg:py-32",children:(0,a.jsxs)("div",{className:"grid gap-12 lg:grid-cols-2 lg:gap-16 items-center",children:[(0,a.jsxs)("div",{className:"space-y-6",children:[(0,a.jsxs)("h1",{className:"text-4xl font-extrabold tracking-tight sm:text-5xl lg:text-6xl",children:["A symbolic reasoning engine",(0,a.jsx)("br",{}),(0,a.jsx)("span",{className:"text-primary",children:"for AI agents"})]}),(0,a.jsx)("p",{className:"text-lg text-muted-foreground max-w-lg",children:"InputLayer is a modern open-source database built on three key concepts:"}),(0,a.jsxs)("ul",{className:"space-y-2 text-muted-foreground",children:[(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(b,{className:"h-5 w-5 text-primary mt-0.5 shrink-0"}),(0,a.jsxs)("span",{children:[(0,a.jsx)("strong",{className:"text-foreground",children:"Knowledge graph"})," - data is stored as facts and relationships, not flat documents"]})]}),(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(v.A,{className:"h-5 w-5 text-primary mt-0.5 shrink-0"}),(0,a.jsxs)("span",{children:[(0,a.jsx)("strong",{className:"text-foreground",children:"Deductive"})," - you define rules, and the system derives everything that logically follows"]})]}),(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(x,{className:"h-5 w-5 text-primary mt-0.5 shrink-0"}),(0,a.jsxs)("span",{children:[(0,a.jsx)("strong",{className:"text-foreground",children:"Streaming"})," - when facts change, all derived conclusions update instantly"]})]})]}),(0,a.jsxs)("div",{className:"flex flex-wrap gap-3 pt-2",children:[(0,a.jsxs)(s(),{href:"/docs/",className:"inline-flex items-center gap-2 rounded-md bg-primary px-5 py-2.5 text-sm font-medium text-primary-foreground hover:bg-primary/90 transition-colors",children:["Read the docs",(0,a.jsx)(w.A,{className:"h-4 w-4"})]}),(0,a.jsxs)("a",{href:"https://github.com/inputlayer/inputlayer",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-md border border-border bg-background px-5 py-2.5 text-sm font-medium hover:bg-secondary transition-colors",children:[(0,a.jsx)(k.A,{className:"h-4 w-4"}),"Star on GitHub"]}),(0,a.jsxs)("a",{href:"https://demo.inputlayer.ai",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-md border border-border bg-background px-5 py-2.5 text-sm font-medium hover:bg-secondary transition-colors",children:["Try the demo",(0,a.jsx)(j.A,{className:"h-3.5 w-3.5"})]})]})]}),(0,a.jsx)("div",{children:(0,a.jsx)(C,{code:T})})]})})]}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"The problem"}),(0,a.jsxs)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:["Vector search ",(0,a.jsx)("span",{className:"underline",children:"only"})," finds things that look like the answer"]}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg",children:"The standard RAG pipeline retrieves documents by similarity. That fails when the answer is connected through a chain of facts - not surface-level similarity."})]}),(0,a.jsxs)("div",{className:"grid gap-6 md:grid-cols-3",children:[(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-3",children:[(0,a.jsxs)("div",{className:"flex items-center gap-2 text-destructive",children:[(0,a.jsx)(N.A,{className:"h-5 w-5"}),(0,a.jsx)("span",{className:"font-semibold",children:"Healthcare"})]}),(0,a.jsxs)("p",{className:"text-sm text-muted-foreground",children:["Patient asks ",(0,a.jsx)("em",{children:"Can I eat shrimp tonight?"})," System finds recipes. Misses the allergy record three hops away: patient takes Drug X  interacts with iodine  shrimp is high in iodine."]}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground/70",children:"Drug  interaction  ingredient  food has zero vector similarity to shrimp dinner."})]}),(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-3",children:[(0,a.jsxs)("div",{className:"flex items-center gap-2 text-warning-foreground",children:[(0,a.jsx)(b,{className:"h-5 w-5"}),(0,a.jsx)("span",{className:"font-semibold",children:"Enterprise"})]}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"Employee asks for Q3 revenue reports. Vector DB returns 40 matching documents. Cannot check whether this employee, in this role, in this department, has permission to see any of them."}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground/70",children:"Access control is a logical question, not a similarity question."})]}),(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-3",children:[(0,a.jsxs)("div",{className:"flex items-center gap-2 text-accent",children:[(0,a.jsx)(A,{className:"h-5 w-5"}),(0,a.jsx)("span",{className:"font-semibold",children:"Financial Services"})]}),(0,a.jsxs)("p",{className:"text-sm text-muted-foreground",children:["Compliance asks ",(0,a.jsx)("em",{children:"Is this transaction suspicious?"})," System finds similar transactions. Misses: Entity A paid Entity B, B is a subsidiary of C, C is on a sanctions list."]}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground/70",children:"Graph traversal + rule evaluation - not pattern matching."})]})]})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"The solution"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"Reasoning, not just similarity"})]}),(0,a.jsxs)("div",{className:"grid gap-12 lg:grid-cols-2 items-start",children:[(0,a.jsxs)("div",{className:"space-y-6",children:[(0,a.jsxs)("p",{className:"text-muted-foreground text-lg",children:[(0,a.jsx)("span",{className:"text-primary font-semibold",children:"InputLayer's query language"})," combines graph traversal, logical rules, and vector search in a single query."]}),(0,a.jsxs)("ul",{className:"space-y-4",children:[(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(g,{className:"h-5 w-5 text-emerald-500 mt-0.5 shrink-0"}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"font-medium",children:"Recursive rule evaluation"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"Define rules like transitive authority. The engine recursively derives all conclusions - including things you never explicitly stored."})]})]}),(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(g,{className:"h-5 w-5 text-emerald-500 mt-0.5 shrink-0"}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"font-medium",children:"Policy-filtered search"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"Logical access control and vector similarity in one pass. Permission-checked and semantically ranked results without glue code."})]})]}),(0,a.jsxs)("li",{className:"flex items-start gap-3",children:[(0,a.jsx)(g,{className:"h-5 w-5 text-emerald-500 mt-0.5 shrink-0"}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"font-medium",children:"One query, multiple capabilities"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"A single query combines vector similarity, graph traversal, and policy evaluation - filling the gaps your current stack can't cover."})]})]})]})]}),(0,a.jsxs)("div",{className:"space-y-3",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-muted-foreground uppercase tracking-wider",children:"Example"}),(0,a.jsx)(C,{code:S}),(0,a.jsxs)("p",{className:"text-sm text-muted-foreground",children:["This query resolves the ",(0,a.jsx)("code",{className:"bg-muted rounded px-1.5 py-0.5 text-xs font-mono",children:"authority"})," rule recursively, runs vector search in the same pass, and returns only documents that Alice has permission to see and that are semantically relevant to her question."]})]})]})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"Under the hood"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"How it works"}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg",children:"InputLayer is built on an incremental computation engine. This gives it three properties that matter for production use."})]}),(0,a.jsxs)("div",{className:"grid gap-6 md:grid-cols-3",children:[(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-4",children:[(0,a.jsx)(x,{className:"h-8 w-8 text-primary"}),(0,a.jsx)("h3",{className:"text-lg font-semibold",children:"Incremental maintenance"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"When a fact changes, only the affected derivations recompute. Insert one new edge into a 2,000-node graph and re-query transitive closure: 6.83ms instead of 11.3 seconds."}),(0,a.jsxs)("div",{className:"text-center pt-2",children:[(0,a.jsx)("span",{className:"text-5xl font-extrabold text-primary",children:"1,652x"}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground mt-1",children:"faster than full recompute"})]})]}),(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-4",children:[(0,a.jsx)(v.A,{className:"h-8 w-8 text-primary"}),(0,a.jsx)("h3",{className:"text-lg font-semibold",children:"Explainable results"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"Every derived fact traces back to the rules and base facts that produced it. Not the vector was close - a full derivation chain you can audit and explain."}),(0,a.jsxs)("div",{className:"text-center pt-2",children:[(0,a.jsx)("span",{className:"text-5xl font-extrabold text-primary",children:"100%"}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground mt-1",children:"of results fully traceable"})]})]}),(0,a.jsxs)("div",{className:"rounded-xl border border-border bg-card p-6 space-y-4",children:[(0,a.jsx)(N.A,{className:"h-8 w-8 text-primary"}),(0,a.jsx)("h3",{className:"text-lg font-semibold",children:"Correct retraction"}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:"Delete a fact and every conclusion derived through it disappears automatically - even through chains of recursive rules. No phantom permissions, no manual cache invalidation."}),(0,a.jsxs)("div",{className:"text-center pt-2",children:[(0,a.jsx)("span",{className:"text-5xl font-extrabold text-primary",children:"0"}),(0,a.jsx)("p",{className:"text-xs text-muted-foreground mt-1",children:"stale results"})]})]})]})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"Comparison"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"The reasoning layer your stack is missing"}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg",children:"Your vector DB finds similar documents. Your graph DB traverses relationships. InputLayer adds what neither can do: rule-based inference, recursive reasoning, and incremental computation."})]}),(0,a.jsx)("div",{className:"overflow-x-auto",children:(0,a.jsxs)("table",{className:"w-full border-collapse text-sm",children:[(0,a.jsx)("thead",{children:(0,a.jsxs)("tr",{className:"border-b border-border",children:[(0,a.jsx)("th",{className:"text-left py-3 px-4 font-semibold",children:"Capability"}),(0,a.jsx)("th",{className:"text-center py-3 px-4 font-semibold text-muted-foreground",children:"Vector DBs"}),(0,a.jsx)("th",{className:"text-center py-3 px-4 font-semibold text-muted-foreground",children:"Graph DBs"}),(0,a.jsx)("th",{className:"text-center py-3 px-4 font-semibold text-muted-foreground",children:"SQL"}),(0,a.jsx)("th",{className:"text-center py-3 px-4 font-semibold text-primary",children:"InputLayer"})]})}),(0,a.jsx)("tbody",{children:[{cap:"Vector similarity",vec:"native",graph:"plugin",sql:"none",il:"native"},{cap:"Graph traversal",vec:"none",graph:"native",sql:"partial",il:"native"},{cap:"Rule-based inference",vec:"none",graph:"none",sql:"none",il:"native"},{cap:"Recursive reasoning",vec:"none",graph:"partial",sql:"partial",il:"native"},{cap:"Incremental updates",vec:"none",graph:"none",sql:"partial",il:"native"},{cap:"Correct retraction",vec:"none",graph:"none",sql:"none",il:"native"},{cap:"Explainable retrieval",vec:"none",graph:"partial",sql:"none",il:"native"}].map(e=>(0,a.jsxs)("tr",{className:"border-b border-border/50",children:[(0,a.jsx)("td",{className:"py-3 px-4",children:e.cap}),(0,a.jsx)("td",{className:"py-3 px-4 text-center",children:(0,a.jsx)("span",{className:"inline-flex justify-center w-full",children:(0,a.jsx)(D,{value:e.vec})})}),(0,a.jsx)("td",{className:"py-3 px-4 text-center",children:(0,a.jsx)("span",{className:"inline-flex justify-center w-full",children:(0,a.jsx)(D,{value:e.graph})})}),(0,a.jsx)("td",{className:"py-3 px-4 text-center",children:(0,a.jsx)("span",{className:"inline-flex justify-center w-full",children:(0,a.jsx)(D,{value:e.sql})})}),(0,a.jsx)("td",{className:"py-3 px-4 text-center",children:(0,a.jsx)("span",{className:"inline-flex justify-center w-full",children:(0,a.jsx)(D,{value:e.il})})})]},e.cap))})]})})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"Use cases"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"Built for reasoning-intensive applications"}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg",children:"From agentic AI to financial compliance, InputLayer powers applications where the answer requires following chains of facts."})]}),(0,a.jsx)("div",{className:"grid gap-6 md:grid-cols-3",children:[{title:"Agentic AI",icon:(0,a.jsx)(v.A,{className:"h-8 w-8 text-primary"}),desc:"Structured memory, multi-hop reasoning, and policy-aware retrieval for AI agents.",href:"/use-cases/agentic-ai/"},{title:"Retail & Commerce",icon:(0,a.jsx)(b,{className:"h-8 w-8 text-primary"}),desc:"Product recommendations, catalog reasoning, and conversational commerce powered by knowledge graphs.",href:"/use-cases/"},{title:"Financial Services",icon:(0,a.jsx)(N.A,{className:"h-8 w-8 text-primary"}),desc:"Sanctions screening, beneficial ownership chains, and transaction monitoring through entity reasoning.",href:"/use-cases/"}].map(e=>(0,a.jsxs)(s(),{href:e.href,className:"group rounded-xl border border-border bg-card p-6 space-y-4 transition-colors hover:border-primary/30 hover:bg-card/80",children:[e.icon,(0,a.jsx)("h3",{className:"text-lg font-semibold group-hover:text-primary transition-colors",children:e.title}),(0,a.jsx)("p",{className:"text-sm text-muted-foreground",children:e.desc}),(0,a.jsxs)("span",{className:"inline-flex items-center gap-1 text-sm text-primary font-medium",children:["Learn more ",(0,a.jsx)(w.A,{className:"h-3.5 w-3.5"})]})]},e.title))})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"max-w-2xl mb-12",children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"Features"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"Everything in the box"})]}),(0,a.jsx)("div",{className:"flex flex-wrap gap-3",children:["55 built-in functions","HNSW vector indexes","Cosine, Euclidean, Dot Product, Manhattan","Recursive queries","Magic Sets optimization","Incremental computation engine","Persistent storage (Parquet + WAL)","Multi-tenancy","WebSocket API","Streaming transport","Python SDK","Object-logic mapper","REST API","Interactive REPL","Session rules","Conditional deletion","Schema validation","Aggregations","Temporal functions","String functions","Math functions","Vector operations","LSH bucketing"].map(e=>(0,a.jsx)(B,{children:e},e))})]})}),d.length>0&&(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsxs)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:[(0,a.jsxs)("div",{className:"flex items-center justify-between mb-12",children:[(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm font-semibold text-primary uppercase tracking-wider mb-2",children:"From the blog"}),(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight",children:"Latest posts"})]}),(0,a.jsxs)(s(),{href:"/blog/",className:"hidden sm:inline-flex items-center gap-1 text-sm text-primary font-medium hover:underline",children:["View all ",(0,a.jsx)(w.A,{className:"h-3.5 w-3.5"})]})]}),(0,a.jsx)("div",{className:"grid gap-6 md:grid-cols-2 lg:grid-cols-3",children:d.slice(0,3).map(e=>(0,a.jsx)(c.Z,{slug:e.slug,title:e.title,date:e.date,author:e.author,excerpt:e.excerpt,category:e.category},e.slug))}),(0,a.jsx)("div",{className:"mt-8 text-center sm:hidden",children:(0,a.jsxs)(s(),{href:"/blog/",className:"inline-flex items-center gap-1 text-sm text-primary font-medium hover:underline",children:["View all posts ",(0,a.jsx)(w.A,{className:"h-3.5 w-3.5"})]})})]})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsx)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:(0,a.jsxs)("div",{className:"max-w-2xl mx-auto text-center space-y-6",children:[(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight",children:"Get started"}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg",children:"Pull the Docker image and start querying in seconds. The query language is intuitive - if you know SQL, the basics take about 10 minutes."}),(0,a.jsx)("div",{className:"text-left mx-auto max-w-2xl",children:(0,a.jsxs)("div",{className:"relative",children:[(0,a.jsx)("pre",{className:"rounded-lg bg-[var(--code-bg)] py-4 px-24 overflow-x-auto text-sm font-mono text-center",children:(0,a.jsxs)("code",{children:[(0,a.jsx)("span",{className:"syn-builtin",children:"docker"})," run -p 8080:8080 ghcr.io/inputlayer/inputlayer"]})}),(0,a.jsx)(I,{text:"docker run -p 8080:8080 ghcr.io/inputlayer/inputlayer"})]})}),(0,a.jsxs)("div",{className:"flex flex-wrap justify-center gap-3 pt-4",children:[(0,a.jsxs)(s(),{href:"/docs/",className:"inline-flex items-center gap-2 rounded-md bg-primary px-5 py-2.5 text-sm font-medium text-primary-foreground hover:bg-primary/90 transition-colors",children:["Read the docs",(0,a.jsx)(w.A,{className:"h-4 w-4"})]}),(0,a.jsxs)("a",{href:"https://demo.inputlayer.ai",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-md border border-border bg-background px-5 py-2.5 text-sm font-medium hover:bg-secondary transition-colors",children:["Try the demo",(0,a.jsx)(j.A,{className:"h-3.5 w-3.5"})]})]})]})})}),(0,a.jsx)("section",{className:"border-b border-border/50",children:(0,a.jsx)("div",{className:"mx-auto max-w-6xl px-6 py-20",children:(0,a.jsxs)("div",{className:"relative rounded-2xl border border-border bg-gradient-to-br from-primary/10 via-transparent to-primary/5 p-12 text-center space-y-6",children:[(0,a.jsx)("h2",{className:"text-3xl font-bold tracking-tight",children:"See it in action"}),(0,a.jsx)("p",{className:"text-muted-foreground text-lg max-w-xl mx-auto",children:"Try InputLayer in your browser. Load a knowledge graph, write rules, and query - no installation required."}),(0,a.jsxs)("div",{className:"flex flex-wrap justify-center gap-3 pt-2",children:[(0,a.jsxs)("a",{href:"https://demo.inputlayer.ai",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-md bg-primary px-6 py-3 text-sm font-medium text-primary-foreground hover:bg-primary/90 transition-colors",children:["Launch demo",(0,a.jsx)(w.A,{className:"h-4 w-4"})]}),(0,a.jsxs)("a",{href:"https://github.com/inputlayer/inputlayer",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-md border border-border bg-background px-6 py-3 text-sm font-medium hover:bg-secondary transition-colors",children:["View on GitHub",(0,a.jsx)(j.A,{className:"h-3.5 w-3.5"})]})]})]})})}),(0,a.jsx)(l.D,{})]})}},8920:(e,t,n)=>{"use strict";n.d(t,{g:()=>i});var a=n(5155),r=n(1337);let s={sm:{icon:20,text:"text-base"},md:{icon:24,text:"text-lg"},lg:{icon:32,text:"text-2xl"}};function i({size:e="md",className:t}){let{icon:n,text:i}=s[e];return(0,a.jsxs)("span",{className:(0,r.cn)("inline-flex items-center gap-1.5",t),children:[(0,a.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:n,height:n,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",className:"flex-shrink-0",children:[(0,a.jsx)("path",{d:"M12 2L2 7l10 5 10-5-10-5z"}),(0,a.jsx)("path",{d:"M2 17l10 5 10-5"}),(0,a.jsx)("path",{d:"M2 12l10 5 10-5"})]}),(0,a.jsx)("span",{className:(0,r.cn)("font-extrabold tracking-tight",i),children:"InputLayer"})]})}}},e=>{e.O(0,[758,441,794,358],()=>e(e.s=6360)),_N_E=e.O()}]);