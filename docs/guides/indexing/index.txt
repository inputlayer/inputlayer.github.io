1:"$Sreact.fragment"
2:I[1942,["177","static/chunks/app/layout-7e9963bf811be36b.js"],"ThemeProvider"]
3:I[7121,[],""]
4:I[4581,[],""]
6:I[484,[],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[484,[],"ViewportBoundary"]
b:I[484,[],"MetadataBoundary"]
d:I[7123,[],""]
:HL["/_next/static/media/4cf2300e9c8272f7-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/4bd7a24b7976d4e6.css","style"]
0:{"P":null,"b":"05bjYGyiAumoEMBrfWHih","c":["","docs","guides","indexing",""],"q":"","i":false,"f":[[["",{"children":["docs",{"children":[["slug","guides/indexing","oc"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/4bd7a24b7976d4e6.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_188709 __variable_9a8899 font-sans antialiased","children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$@a"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$@c"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$d",[]],"S":true}
e:I[8428,["758","static/chunks/758-3cb69ce377cde046.js","121","static/chunks/121-aece4f809b101dc1.js","502","static/chunks/502-e809071f8789437b.js","689","static/chunks/689-4fcf9680fdc90283.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-004ec69e3c86920a.js"],"DocsPageClient"]
f:T208e,# Indexing Guide

InputLayer provides HNSW (Hierarchical Navigable Small World) indexes for fast approximate nearest neighbor search on vector data.

## Why Use Indexes?

Without an index, vector similarity queries perform a linear scan:
- **10K vectors**: ~10ms
- **100K vectors**: ~100ms
- **1M vectors**: ~1s

With an HNSW index:
- **10K vectors**: ~1ms
- **100K vectors**: ~5ms
- **1M vectors**: ~10ms

**Trade-off**: Indexes use memory and may return approximate (not exact) results.

---

## Creating an Index

### Basic Syntax

```
.index create <name> on <relation>(<column>) [options]
```

### Simple Example

```datalog
// Create a documents table with embeddings
+documents(id: int, title: string, embedding: vector)

// Insert some documents
+documents(1, "Introduction to ML", [0.1, 0.2, 0.3, 0.4])
+documents(2, "Vector Databases", [0.15, 0.25, 0.28, 0.42])
+documents(3, "Graph Theory", [0.8, 0.1, 0.05, 0.05])
```

```
.index create doc_emb_idx on documents(embedding)
```

### With Options

```
.index create doc_emb_idx on documents(embedding) metric cosine m 16 ef_search 50
```

---

## Index Options

### Distance Metrics

| Metric | Aliases | Use Case |
|--------|---------|----------|
| `cosine` | `cos` | Text embeddings (most common) |
| `euclidean` | `l2`, `euclid` | Image embeddings |
| `dot` | `dotproduct`, `inner` | When vectors have meaningful magnitude |
| `manhattan` | `l1`, `taxicab` | Sparse vectors |

**Default**: `cosine`

```
.index create my_idx on vectors(embedding) metric l2
.index create my_idx on vectors(embedding) metric cosine
.index create my_idx on vectors(embedding) metric dot
```

### HNSW Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `m` | 16 | Max connections per node (higher = better recall, more memory) |
| `ef_construction` | 200 | Construction-time ef (higher = better quality, slower build) |
| `ef_search` | 50 | Search-time ef (higher = better recall, slower search) |

```
.index create my_idx on vectors(embedding) m 32 ef_search 100
```

### Parameter Tuning

**For higher recall (more accurate results):**
```
.index create my_idx on vectors(embedding) m 32 ef_construction 400 ef_search 100
```

**For faster search (lower recall):**
```
.index create my_idx on vectors(embedding) m 8 ef_search 20
```

**For large datasets (millions of vectors):**
```
.index create my_idx on vectors(embedding) m 48 ef_construction 500 ef_search 200
```

---

## Managing Indexes

### List All Indexes

```
.index
```

or

```
.index list
```

**Output:**

| Name | Relation | Column | Type | Metric | Valid |
|---|---|---|---|---|---|
| doc_emb_idx | documents | embedding | hnsw | cosine | yes |

### View Index Statistics

```
.index stats doc_emb_idx
```

**Output:**
```
Index: doc_emb_idx
  Relation:   documents
  Column:     embedding
  Type:       hnsw
  Metric:     cosine
  Vectors:    10000
  Dimension:  768
  Valid:      yes
  Tombstones: 0
  Built:      2024-01-15 10:30:00
```

### Rebuild an Index

After many insertions/deletions, an index may become fragmented. Rebuild to optimize:

```
.index rebuild doc_emb_idx
```

### Drop an Index

```
.index drop doc_emb_idx
```

---

## Using Indexes in Queries

Use the `hnsw_nearest()` predicate in query bodies to perform fast approximate nearest-neighbor search via an HNSW index.

### Syntax

```
hnsw_nearest("index_name", QueryVec, K, IdVar, DistVar [, EfSearch])
```

- `index_name` — String literal naming the HNSW index
- `QueryVec` — Variable bound to a vector, or a vector literal `[1.0, 2.0]`
- `K` — Integer: number of nearest neighbors
- `IdVar` — Variable to bind result tuple IDs
- `DistVar` — Variable to bind distances
- `EfSearch` — Optional integer: override ef_search for this query

### Examples

```datalog
// Find 5 nearest documents to a literal query vector
? hnsw_nearest("doc_emb_idx", [0.11, 0.21, 0.29], 5, Id, Dist)

// Use a bound query vector and join with base data
? query_vec(QV), hnsw_nearest("doc_emb_idx", QV, 10, Id, Dist), documents(Id, Title, _)

// Override ef_search for higher recall
? hnsw_nearest("doc_emb_idx", [0.11, 0.21, 0.29], 5, Id, Dist, 200)
```

**Note:** Indexes are not used automatically — you must explicitly call `hnsw_nearest()` to use an HNSW index.

---

## Index Lifecycle

### Build Phase

When you create an index, vectors are inserted incrementally:

1. Index is registered with metadata
2. Existing vectors are added to the HNSW structure
3. Index is marked as valid

### Invalidation

Indexes are automatically invalidated when:
- Base relation is modified (insert/delete)
- Schema changes

```
.index stats my_idx
  Valid: no  ← Index needs rebuild
```

### Rebuild

Invalid indexes are rebuilt on:
- Explicit `.index rebuild` command
- Next query that uses the index

---

## Index Architecture

### HNSW Structure

```
Layer 3:  *-------------*
          |             |
Layer 2:  *---*-----*---*---*
          |   |     |   |   |
Layer 1:  *-*-*-*-*-*-*-*-*-*-*
          | | | | | | | | | | |
Layer 0:  *********************** (all nodes)
```

Each layer has fewer nodes. Search starts at top layer and descends:
1. Find nearest nodes in current layer
2. Use those as entry points for next layer
3. Repeat until layer 0
4. Return k nearest neighbors

### Memory Usage

HNSW indexes use approximately:

```
memory approx n * (d * 4 + m * 8) bytes
```

Where:
- `n` = number of vectors
- `d` = vector dimension
- `m` = max connections parameter

**Example**: 1M vectors × 768 dimensions × m=16:
```
1M × (768 × 4 + 16 × 8) = ~3.2 GB
```

---

## Tombstones and Compaction

When vectors are deleted, they're marked with a tombstone rather than removed immediately:

```
.index stats my_idx
  Vectors:    10000
  Tombstones: 500  ← Deleted entries not yet cleaned up
```

### Automatic Compaction

When the tombstone ratio exceeds 30%, the index is automatically rebuilt inline during the delete operation.

### Manual Compaction

Force a rebuild to remove tombstones:

```
.index rebuild my_idx
```

---

## Best Practices

### 1. Choose the Right Metric

| Embedding Type | Recommended Metric |
|---------------|-------------------|
| OpenAI embeddings | `cosine` |
| BERT/Sentence-BERT | `cosine` |
| Image embeddings (CLIP) | `cosine` |
| Raw feature vectors | `euclidean` |
| Pre-normalized vectors | `dot` (fastest) |

### 2. Tune Parameters for Your Use Case

**Discovery/Exploration** (higher recall matters):
```
.index create my_idx on docs(emb) m 32 ef_search 100
```

**Production/Speed** (latency matters):
```
.index create my_idx on docs(emb) m 16 ef_search 30
```

### 3. Monitor Index Health

Regularly check:
```
.index stats my_idx
```

Rebuild if:
- Tombstone ratio > 30%
- Search quality degrades
- After bulk insertions

### 4. Create Indexes Before Bulk Load

For large initial loads, create the index first:

```datalog
.index create my_idx on docs(emb)

// Then bulk insert
+docs[(1, "...", [0.1, ...]),
      (2, "...", [0.2, ...]),
      ...]
```

### 5. Use Appropriate Vector Dimensions

Common dimensions:
- OpenAI text-embedding-3-small: 1536
- Cohere embed-english-v3: 1024
- all-MiniLM-L6-v2: 384
- CLIP ViT-B/32: 512

Higher dimensions = more memory, slower search.

---

## Troubleshooting

### Index Shows "Invalid"

**Cause**: Base relation was modified.

**Solution**:
```
.index rebuild my_idx
```

### Search Returns No Results

**Possible causes**:
1. Index not yet built
2. Query vector dimension mismatch
3. No vectors in relation

**Debug**:
```datalog
.index stats my_idx
? documents(Id, _, V)  // Check if data exists
```

### Poor Search Quality

**Causes**:
1. Wrong distance metric for embedding type
2. ef_search too low
3. Many tombstones

**Solutions**:
```datalog
// Check metric matches embedding type
.index stats my_idx

// Increase ef_search
.index create my_idx on docs(emb) ef_search 100

// Rebuild to remove tombstones
.index rebuild my_idx
```

### High Memory Usage

**Solutions**:
1. Reduce `m` parameter (trades recall for memory)
2. Use vector quantization (see [Vectors Guide](vectors))
3. Consider approximate embeddings with lower dimensions

---

## Next Steps

- [Vector Search Tutorial](vectors) - Distance functions and semantic search
- [Configuration Guide](configuration) - Index persistence settings5:["$","$Le",null,{"page":{"title":"Indexing Guide","content":"$f","toc":[{"level":2,"text":"Why Use Indexes?","id":"why-use-indexes"},{"level":2,"text":"Creating an Index","id":"creating-an-index"},{"level":3,"text":"Basic Syntax","id":"basic-syntax"},{"level":3,"text":"Simple Example","id":"simple-example"},{"level":3,"text":"With Options","id":"with-options"},{"level":2,"text":"Index Options","id":"index-options"},{"level":3,"text":"Distance Metrics","id":"distance-metrics"},{"level":3,"text":"HNSW Parameters","id":"hnsw-parameters"},{"level":3,"text":"Parameter Tuning","id":"parameter-tuning"},{"level":2,"text":"Managing Indexes","id":"managing-indexes"},{"level":3,"text":"List All Indexes","id":"list-all-indexes"},{"level":3,"text":"View Index Statistics","id":"view-index-statistics"},{"level":3,"text":"Rebuild an Index","id":"rebuild-an-index"},{"level":3,"text":"Drop an Index","id":"drop-an-index"},{"level":2,"text":"Using Indexes in Queries","id":"using-indexes-in-queries"},{"level":3,"text":"Syntax","id":"syntax"},{"level":3,"text":"Examples","id":"examples"},{"level":2,"text":"Index Lifecycle","id":"index-lifecycle"},{"level":3,"text":"Build Phase","id":"build-phase"},{"level":3,"text":"Invalidation","id":"invalidation"},{"level":3,"text":"Rebuild","id":"rebuild"},{"level":2,"text":"Index Architecture","id":"index-architecture"},{"level":3,"text":"HNSW Structure","id":"hnsw-structure"},{"level":3,"text":"Memory Usage","id":"memory-usage"},{"level":2,"text":"Tombstones and Compaction","id":"tombstones-and-compaction"},{"level":3,"text":"Automatic Compaction","id":"automatic-compaction"},{"level":3,"text":"Manual Compaction","id":"manual-compaction"},{"level":2,"text":"Best Practices","id":"best-practices"},{"level":3,"text":"1. Choose the Right Metric","id":"1-choose-the-right-metric"},{"level":3,"text":"2. Tune Parameters for Your Use Case","id":"2-tune-parameters-for-your-use-case"},{"level":3,"text":"3. Monitor Index Health","id":"3-monitor-index-health"},{"level":3,"text":"4. Create Indexes Before Bulk Load","id":"4-create-indexes-before-bulk-load"},{"level":3,"text":"5. Use Appropriate Vector Dimensions","id":"5-use-appropriate-vector-dimensions"},{"level":2,"text":"Troubleshooting","id":"troubleshooting"},{"level":3,"text":"Index Shows \"Invalid\"","id":"index-shows-invalid"},{"level":3,"text":"Search Returns No Results","id":"search-returns-no-results"},{"level":3,"text":"Poor Search Quality","id":"poor-search-quality"},{"level":3,"text":"High Memory Usage","id":"high-memory-usage"},{"level":2,"text":"Next Steps","id":"next-steps"}]},"slugKey":"guides/indexing"}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
10:I[6869,[],"IconMark"]
c:[["$","title","0",{"children":"InputLayer - A symbolic reasoning engine for AI agents"}],["$","meta","1",{"name":"description","content":"Store facts, define rules, and derive everything that logically follows. Vector search, graph traversal, and incremental computation in one system."}],["$","link","2",{"rel":"icon","href":"/icon.svg"}],["$","$L10","3",{}]]
8:null
