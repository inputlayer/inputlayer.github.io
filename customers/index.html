<!DOCTYPE html><!--05bjYGyiAumoEMBrfWHih--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/4bd7a24b7976d4e6.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-bd6546b43ab2ecbf.js"/><script src="/_next/static/chunks/4bd1b696-deba172d32c79f82.js" async=""></script><script src="/_next/static/chunks/794-275dc9ebd3a29fbf.js" async=""></script><script src="/_next/static/chunks/main-app-1fa5b694e5d36a75.js" async=""></script><script src="/_next/static/chunks/app/layout-7e9963bf811be36b.js" async=""></script><script src="/_next/static/chunks/758-3cb69ce377cde046.js" async=""></script><script src="/_next/static/chunks/830-dbae36b1030f3d7c.js" async=""></script><script src="/_next/static/chunks/app/customers/page-f2bfa7b04ee51f7a.js" async=""></script><meta name="next-size-adjust" content=""/><title>InputLayer - A symbolic reasoning engine for AI agents</title><meta name="description" content="Store facts, define rules, and derive everything that logically follows. Vector search, graph traversal, and incremental computation in one system."/><link rel="icon" href="/icon.svg"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_188709 __variable_9a8899 font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><div class="flex flex-col min-h-dvh"><header class="sticky top-0 z-50 w-full border-b border-border/50 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="flex h-14 items-center px-6"><a class="mr-8" href="/"><span class="inline-flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="flex-shrink-0"><path d="M12 2L2 7l10 5 10-5-10-5z"></path><path d="M2 17l10 5 10-5"></path><path d="M2 12l10 5 10-5"></path></svg><span class="font-extrabold tracking-tight text-lg">InputLayer</span></span></a><nav class="hidden md:flex items-center gap-6 text-sm"><a class="text-muted-foreground transition-colors hover:text-foreground" href="/docs/">Docs</a><a class="text-muted-foreground transition-colors hover:text-foreground" href="/blog/">Blog</a><a class="text-muted-foreground transition-colors hover:text-foreground" href="/use-cases/">Use Cases</a><a class="text-muted-foreground transition-colors hover:text-foreground" href="/compare/">Compare</a><a href="https://demo.inputlayer.ai" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-muted-foreground transition-colors hover:text-foreground">Demo<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></nav><div class="ml-auto flex items-center gap-3"><div class="inline-flex items-center gap-1.5"><a href="https://github.com/inputlayer/inputlayer" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 rounded-md border border-border bg-secondary/50 px-2.5 py-1 text-xs font-medium text-muted-foreground transition-colors hover:text-foreground hover:bg-secondary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-star h-3.5 w-3.5"><path d="M11.525 2.295a.53.53 0 0 1 .95 0l2.31 4.679a2.123 2.123 0 0 0 1.595 1.16l5.166.756a.53.53 0 0 1 .294.904l-3.736 3.638a2.123 2.123 0 0 0-.611 1.878l.882 5.14a.53.53 0 0 1-.771.56l-4.618-2.428a2.122 2.122 0 0 0-1.973 0L6.396 21.01a.53.53 0 0 1-.77-.56l.881-5.139a2.122 2.122 0 0 0-.611-1.879L2.16 9.795a.53.53 0 0 1 .294-.906l5.165-.755a2.122 2.122 0 0 0 1.597-1.16z"></path></svg><span>Star</span></a><a href="https://github.com/inputlayer/inputlayer/fork" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 rounded-md border border-border bg-secondary/50 px-2.5 py-1 text-xs font-medium text-muted-foreground transition-colors hover:text-foreground hover:bg-secondary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-git-fork h-3.5 w-3.5"><circle cx="12" cy="18" r="3"></circle><circle cx="6" cy="6" r="3"></circle><circle cx="18" cy="6" r="3"></circle><path d="M18 9v2c0 .6-.4 1-1 1H7c-.6 0-1-.4-1-1V9"></path><path d="M12 12v3"></path></svg><span>Fork</span></a></div><button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9 h-9 w-9"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun h-4 w-4"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button><div class="md:hidden"><button class="inline-flex items-center justify-center rounded-md p-2 text-muted-foreground hover:text-foreground hover:bg-secondary transition-colors" aria-label="Open menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button></div></div></div></header><main class="flex-1"><section class="border-b border-border/50"><div class="relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-b from-primary/5 to-transparent"></div><div class="relative mx-auto max-w-6xl px-6 py-16 lg:py-20"><h1 class="text-3xl font-extrabold tracking-tight sm:text-4xl lg:text-5xl max-w-3xl">Customer Stories</h1><p class="mt-4 text-lg text-muted-foreground max-w-2xl">See how teams use InputLayer in production.</p></div></div></section><section class="mx-auto max-w-6xl px-6 py-12"><div class="grid gap-6 md:grid-cols-2"><a class="group rounded-xl border border-border bg-card p-6 space-y-4 transition-colors hover:border-primary/30 hover:bg-card/80" href="/customers/semantic-image-knowledge-graph/"><span class="inline-flex items-center rounded-full border border-border bg-secondary/50 px-2.5 py-0.5 text-xs font-medium text-muted-foreground">Media</span><h3 class="text-lg font-semibold group-hover:text-primary transition-colors">Semantic Image Knowledge Graph</h3><p class="text-2xl font-extrabold text-primary">Millions of images indexed</p><span class="inline-flex items-center gap-1 text-sm text-primary font-medium">Read story <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-3.5 w-3.5"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></span></a><a class="group rounded-xl border border-border bg-card p-6 space-y-4 transition-colors hover:border-primary/30 hover:bg-card/80" href="/customers/warehouse-optimization/"><span class="inline-flex items-center rounded-full border border-border bg-secondary/50 px-2.5 py-0.5 text-xs font-medium text-muted-foreground">Manufacturing</span><h3 class="text-lg font-semibold group-hover:text-primary transition-colors">Warehouse Optimization</h3><p class="text-2xl font-extrabold text-primary">&lt;50ms reasoning latency</p><span class="inline-flex items-center gap-1 text-sm text-primary font-medium">Read story <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-3.5 w-3.5"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></span></a></div></section><section class="border-t border-border/50"><div class="mx-auto max-w-6xl px-6 py-16"><div class="relative rounded-2xl border border-border bg-gradient-to-br from-primary/10 via-transparent to-primary/5 p-12 text-center space-y-6"><h2 class="text-3xl font-bold tracking-tight">Ready to get started?</h2><p class="text-muted-foreground text-lg max-w-xl mx-auto">InputLayer is open-source. Pull the Docker image and start building.</p><div class="flex flex-wrap justify-center gap-3 pt-2"><a class="inline-flex items-center gap-2 rounded-md bg-primary px-6 py-3 text-sm font-medium text-primary-foreground hover:bg-primary/90 transition-colors" href="/docs/">Read the docs<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a><a href="https://github.com/inputlayer/inputlayer" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 rounded-md border border-border bg-background px-6 py-3 text-sm font-medium hover:bg-secondary transition-colors">View on GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3.5 w-3.5"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></section></main><footer class="border-t border-border/50 bg-card/50"><div class="mx-auto max-w-6xl px-6 py-12"><div class="grid grid-cols-2 gap-8 md:grid-cols-4 lg:gap-12"><div><h3 class="text-sm font-semibold text-foreground mb-3">Product</h3><ul class="space-y-2"><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/#features">Features</a></li><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/use-cases/">Use Cases</a></li><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/compare/">Compare</a></li><li><a href="https://demo.inputlayer.ai" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors">Demo<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></li></ul></div><div><h3 class="text-sm font-semibold text-foreground mb-3">Resources</h3><ul class="space-y-2"><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/docs/">Documentation</a></li><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/blog/">Blog</a></li><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/docs/guides/quickstart/">Quickstart</a></li><li><a class="text-sm text-muted-foreground hover:text-foreground transition-colors" href="/docs/guides/python-sdk/">Python SDK</a></li></ul></div><div><h3 class="text-sm font-semibold text-foreground mb-3">Company</h3><ul class="space-y-2"><li><a href="https://github.com/inputlayer/inputlayer" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors">GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></li><li><a href="https://github.com/inputlayer/inputlayer/blob/main/LICENSE" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors">License<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></li></ul></div><div><h3 class="text-sm font-semibold text-foreground mb-3">Community</h3><ul class="space-y-2"><li><a href="https://github.com/inputlayer/inputlayer" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors">Star on GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></li><li><a href="https://github.com/inputlayer/inputlayer/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-muted-foreground hover:text-foreground transition-colors">Contributing<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></li></ul></div></div><div class="mt-10 flex flex-col sm:flex-row items-center justify-between gap-4 border-t border-border/50 pt-8"><div class="flex items-center gap-4"><span class="inline-flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="flex-shrink-0"><path d="M12 2L2 7l10 5 10-5-10-5z"></path><path d="M2 17l10 5 10-5"></path><path d="M2 12l10 5 10-5"></path></svg><span class="font-extrabold tracking-tight text-base">InputLayer</span></span><span class="text-sm text-muted-foreground">AGPL-3.0 License</span></div><p class="text-xs text-muted-foreground">A symbolic reasoning engine for AI agents.</p></div></div></footer></div><!--$--><!--/$--><script src="/_next/static/chunks/webpack-bd6546b43ab2ecbf.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[1942,[\"177\",\"static/chunks/app/layout-7e9963bf811be36b.js\"],\"ThemeProvider\"]\n3:I[7121,[],\"\"]\n4:I[4581,[],\"\"]\n5:I[3384,[\"758\",\"static/chunks/758-3cb69ce377cde046.js\",\"830\",\"static/chunks/830-dbae36b1030f3d7c.js\",\"812\",\"static/chunks/app/customers/page-f2bfa7b04ee51f7a.js\"],\"CustomersIndexClient\"]\na:I[7123,[],\"\"]\n:HL[\"/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/4bd7a24b7976d4e6.css\",\"style\"]\n6:T117d,"])</script><script>self.__next_f.push([1,"\n# Semantic Image Knowledge Graph\n\nA European photo company manages one of the largest stock photo libraries on the continent. With millions of images in their collection, they needed a way to go beyond simple keyword tagging and let customers discover images through the *relationships* between them - not just surface-level similarity.\n\nThey added InputLayer as the reasoning layer for their image discovery system, combining vector similarity (finding visually similar images) with structural queries (understanding what's *in* the images and how those things relate to each other).\n\n## The challenge\n\nStock photo libraries have traditionally relied on manual tagging. This approach has two well-known limitations.\n\n```steps\nTagging is expensive and inconsistent :: Different editors tag the same image differently. Volume makes thorough tagging impossible.\nKeyword search misses conceptual relationships :: A customer searching \"business meeting diversity\" won't find images unless that exact phrase was tagged. The concept exists in the image, but not in the metadata.\n```\n\nThe company had already implemented vector search using image embeddings, which helped with visual similarity. You could find images that *looked like* a reference image. But they wanted to go further - they wanted customers to search by the *concepts and relationships* within images.\n\n## The solution\n\nInputLayer was added alongside their existing image processing pipeline. The pipeline extracts structured information from images using computer vision models - detected objects, scenes, colors, compositions, people attributes. These structured outputs are stored as facts in InputLayer's knowledge graph.\n\nSo for each image, InputLayer knows things like: \"this image contains a person and a laptop and a coffee cup,\" \"the scene is an office,\" \"there's a woman in her 30s who appears to be typing.\" Each of these is a structured fact, not a free-text tag. And because they're structured, the reasoning engine can query across them in powerful ways.\n\n## Combining vector search with structural queries\n\nThe real power comes from combining these two approaches in a single query.\n\n```tree\nQuery: \"images with warm lighting showing collaborative work\" [primary]\n  Vector similarity\n    Finds images with similar visual style (warm lighting, professional) [success]\n  Structural query\n    Finds images with multiple people + shared object (whiteboard, laptop) [success]\n  Combined result\n    Images matching both visual style AND content relationships [primary]\n```\n\nA customer uploads a reference image and asks: \"find images with a similar style that also show people in an office setting.\" The vector similarity captures the visual style and composition, while the structural constraints ensure the content matches. Both conditions are evaluated in a single pass.\n\nMore sophisticated queries can traverse relationships between concepts. A customer searching for \"collaborative work\" might want images showing multiple people interacting with a shared object. This kind of query is impossible with pure vector search because it requires reasoning about the *relationships* between detected entities - not just whether certain objects are present, but how they relate to each other.\n\n## Results\n\n```steps\nVisual style + conceptual content :: Customers can search by both simultaneously [success]\nRelationship-based discovery :: Find images based on how objects and people relate in the scene [primary]\nIncremental updates :: New images immediately queryable, removed images retract cleanly [success]\nMillions of images indexed :: Combined vector and structural queries at scale [primary]\n```\n\nThe incremental computation engine keeps the knowledge graph current as new images are processed. When the vision pipeline extracts structured data from a new image, the facts are added and immediately available for queries. When an image is removed, all its associated facts retract cleanly - no orphaned metadata.\n\n## Key technical insight\n\n```note\ntype: tip\nThe key design decision was treating image understanding as a knowledge graph problem, not a pure embedding problem. Vector embeddings capture visual similarity well, but they compress away the structured information about what's in the image. By extracting that structure and storing it as facts, the company made it queryable through logical reasoning - and the combination turned out to be much more powerful than either approach alone.\n```"])</script><script>self.__next_f.push([1,"7:Te8b,"])</script><script>self.__next_f.push([1,"\n# Warehouse Optimization\n\nA European appliance manufacturer needed real-time reasoning for their warehouse operations. Their existing databases handled inventory tracking and order management well, but when it came to making fast, logic-heavy decisions - like optimal pick routing and dynamic re-prioritization - the application layer was doing too much heavy lifting.\n\nThey added InputLayer as the reasoning layer on top of their existing infrastructure, and the results were immediate: sub-50ms query latency for decisions that previously took hundreds of milliseconds to assemble from multiple data sources.\n\n## The challenge\n\nThe company operates large-scale distribution centers across Europe. Their existing systems were solid for what they were designed to do - track inventory levels, manage orders, store warehouse layouts. The problem wasn't with those systems. It was with the gap between them.\n\n```flow\nPicking robot needs route -\u003e Inventory DB [primary] -\u003e Order priority DB -\u003e Layout DB -\u003e Application code stitches it all together [highlight]\n```\n\nWhen a picking robot needed to determine the optimal route, the application layer had to pull data from inventory, cross-reference it with order priorities, factor in the physical layout, and compute a path. All of this logic lived in application code, making separate queries to different systems.\n\nThis added hundreds of milliseconds to each decision. For a warehouse running thousands of picks per hour, those milliseconds add up fast.\n\n## The solution\n\nInputLayer was added as a dedicated reasoning layer sitting alongside the existing infrastructure. Warehouse layout, inventory positions, and order priorities are ingested as facts. The routing and optimization logic that used to live in scattered application code is now expressed as reasoning rules that the engine evaluates in real time.\n\nHere's what that looks like conceptually. The warehouse layout is represented as a graph - bins connected to aisles, aisles connected to docks. Inventory tells the engine what's in each bin. Order priorities tell it what needs to be picked first. And the routing rules compute optimal paths through this graph, taking all of these factors into account simultaneously.\n\nThe key part is that the path computation is recursive - the engine explores routes through the warehouse graph, finding how to get from the dock to each bin that has items needed for high-priority orders. It evaluates this in one pass rather than requiring the application to make separate calls to different systems.\n\n## Results\n\n```steps\nRouting decisions :: Under 50ms (previously hundreds of ms) [success]\nInventory change propagation :: Only affected routes recompute [primary]\nStale route elimination :: Automatic - no robots sent to empty bins [success]\n```\n\nThe impact was felt almost immediately. Query latency dropped to under 50ms for routing decisions that previously required multiple round-trips between systems.\n\nThe incremental computation engine turned out to be especially valuable. When inventory changes (which happens constantly in a busy warehouse), only the affected routes recompute. No need to rebuild the entire routing graph every time someone picks an item. And when an item is fully picked, the correct retraction mechanism ensures that all dependent routing decisions update automatically.\n\n## Key technical insight\n\n```note\ntype: tip\nThe recursive path computation through the warehouse graph is what makes this practical. InputLayer's incremental computation means adding or removing inventory doesn't require recomputing all paths - only the affected routes update. This is what keeps latency under 50ms even as the warehouse state changes continuously.\n```"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"05bjYGyiAumoEMBrfWHih\",\"c\":[\"\",\"customers\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"customers\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4bd7a24b7976d4e6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_188709 __variable_9a8899 font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L5\",null,{\"stories\":[{\"slug\":\"semantic-image-knowledge-graph\",\"title\":\"Semantic Image Knowledge Graph\",\"industry\":\"Media\",\"keyMetric\":\"Millions of images indexed\",\"content\":\"$6\",\"toc\":[{\"level\":2,\"text\":\"The challenge\",\"id\":\"the-challenge\"},{\"level\":2,\"text\":\"The solution\",\"id\":\"the-solution\"},{\"level\":2,\"text\":\"Combining vector search with structural queries\",\"id\":\"combining-vector-search-with-structural-queries\"},{\"level\":2,\"text\":\"Results\",\"id\":\"results\"},{\"level\":2,\"text\":\"Key technical insight\",\"id\":\"key-technical-insight\"}]},{\"slug\":\"warehouse-optimization\",\"title\":\"Warehouse Optimization\",\"industry\":\"Manufacturing\",\"keyMetric\":\"\u003c50ms reasoning latency\",\"content\":\"$7\",\"toc\":[{\"level\":2,\"text\":\"The challenge\",\"id\":\"the-challenge\"},{\"level\":2,\"text\":\"The solution\",\"id\":\"the-solution\"},{\"level\":2,\"text\":\"Results\",\"id\":\"results\"},{\"level\":2,\"text\":\"Key technical insight\",\"id\":\"key-technical-insight\"}]}]}],null,\"$L8\"]}],{},null,false,false]},null,false,false]},null,false,false],\"$L9\",false]],\"m\":\"$undefined\",\"G\":[\"$a\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"b:I[484,[],\"OutletBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[484,[],\"ViewportBoundary\"]\n10:I[484,[],\"MetadataBoundary\"]\n8:[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$c\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@d\"}]}]\n9:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$Le\",null,{\"children\":\"$@f\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L10\",null,{\"children\":[\"$\",\"$c\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@11\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"12:I[6869,[],\"IconMark\"]\n11:[[\"$\",\"title\",\"0\",{\"children\":\"InputLayer - A symbolic reasoning engine for AI agents\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Store facts, define rules, and derive everything that logically follows. Vector search, graph traversal, and incremental computation in one system.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/icon.svg\"}],[\"$\",\"$L12\",\"3\",{}]]\nd:null\n"])</script></body></html>